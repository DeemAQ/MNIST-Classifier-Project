{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T4CDn79l2Yu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
        "\n",
        "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
        "\n",
        "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
        "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
        "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
        "\n",
        "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "41EfstGFl2Yv"
      },
      "outputs": [],
      "source": [
        "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb7Z-geNjsqQ",
        "outputId": "4ee7cb3a-84fb-4674-bd85-fcd735571c2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr4b9bBgl2Yx"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "Specify your transforms as a list if you intend to .\n",
        "The transforms module is already loaded as `transforms`.\n",
        "\n",
        "MNIST is fortunately included in the torchvision module.\n",
        "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
        "Make sure to specify `download=True`!\n",
        "\n",
        "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "egZoy8cVl2Yx"
      },
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "norm = transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "transform = transforms.Compose([transforms.ToTensor(), norm])\n",
        "\n",
        "# Create training set and define training dataloader\n",
        "train_data = torchvision.datasets.MNIST(\n",
        "    root=\"./mnist\",\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# Create test set and define test dataloader\n",
        "test_data = torchvision.datasets.MNIST(\n",
        "    root=\"./mnist\",\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1NFrVLHl2Yx"
      },
      "source": [
        "## Justify your preprocessing\n",
        "\n",
        "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?\n",
        "\n",
        "I used:\n",
        "1. `transforms.ToTensor()`: This transform converts the input image from the PIL to PyTorch tensor, which is the expected input format for neural networks in PyTorch.\n",
        "\n",
        "2. `transforms.Normalize(mean=[0.5], std=[0.5])`: This transform normalizes the tensor values of the image with the mean and standard deviation of the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89XCUO7nl2Yy"
      },
      "source": [
        "## Explore the Dataset\n",
        "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
        "\n",
        "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
        "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
        "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
        "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ioJg-ALil2Yy"
      },
      "outputs": [],
      "source": [
        "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
        "def show5(img_loader):\n",
        "    dataiter = iter(img_loader)\n",
        "\n",
        "    batch = next(dataiter)\n",
        "    labels = batch[1][0:5]\n",
        "    images = batch[0][0:5]\n",
        "    for i in range(5):\n",
        "        print(int(labels[i].detach()))\n",
        "\n",
        "        image = images[i].numpy()\n",
        "        plt.imshow(image.T.squeeze().T)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yz9D66yIl2Yy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c37e29cf-f06e-4fa4-ad1b-c997391216f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Explore data\n",
        "show5(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7rwYkOsl2Yy"
      },
      "source": [
        "## Build your Neural Network\n",
        "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
        "Use any architecture you like.\n",
        "\n",
        "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "regcY0lyl2Yy"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320) # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OpT_mvnl2Yy"
      },
      "source": [
        "Specify a loss function and an optimizer, and instantiate the model.\n",
        "\n",
        "If you use a less common loss function, please note why you chose that loss function in a comment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbYwxIjcjpHJ",
        "outputId": "d7711d85-cc9e-4712-885b-3786e5a20047"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    momentum=momentum,\n",
        "    weight_decay=0.0005\n",
        "    )\n",
        "\n",
        "criterion = nn.NLLLoss().to(device)"
      ],
      "metadata": {
        "id": "BiQWoue5jzMy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q02j-eBl2Yz"
      },
      "source": [
        "## Running your Neural Network\n",
        "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch.\n",
        "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
        "\n",
        "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 35\n",
        "steps = 0\n",
        "train_loss = 0\n",
        "print_every = 5\n",
        "\n",
        "train_loss_history = list()\n",
        "valid_loss_history = list()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images.requires_grad = True\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        train_loss_history.append(train_loss/len(train_loader))\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            valid_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    images.requires_grad = True\n",
        "\n",
        "                    logits = model(images)\n",
        "                    batch_loss = criterion(logits, labels)\n",
        "                    valid_loss += batch_loss.item()\n",
        "\n",
        "                    valid_loss_history.append(valid_loss/len(test_loader))\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    probs = torch.exp(logits)\n",
        "                    _, top_class = probs.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Training Loss: {train_loss/print_every:.3f}.. \"\n",
        "                  f\"Validation Loss: {valid_loss/len(test_loader):.3f}.. \"\n",
        "                  f\"Accuracy: {accuracy/len(test_loader):.3f}\")\n",
        "            train_loss = 0\n",
        "            model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JorG7gsFlPK3",
        "outputId": "b1254437-613d-4b42-eae7-3f9dde1e6486"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35.. Training Loss: 2.308.. Validation Loss: 2.305.. Accuracy: 0.101\n",
            "Epoch 1/35.. Training Loss: 2.307.. Validation Loss: 2.304.. Accuracy: 0.106\n",
            "Epoch 1/35.. Training Loss: 2.304.. Validation Loss: 2.303.. Accuracy: 0.113\n",
            "Epoch 1/35.. Training Loss: 2.306.. Validation Loss: 2.302.. Accuracy: 0.121\n",
            "Epoch 1/35.. Training Loss: 2.302.. Validation Loss: 2.301.. Accuracy: 0.128\n",
            "Epoch 1/35.. Training Loss: 2.309.. Validation Loss: 2.300.. Accuracy: 0.135\n",
            "Epoch 1/35.. Training Loss: 2.306.. Validation Loss: 2.299.. Accuracy: 0.139\n",
            "Epoch 1/35.. Training Loss: 2.301.. Validation Loss: 2.298.. Accuracy: 0.143\n",
            "Epoch 1/35.. Training Loss: 2.305.. Validation Loss: 2.297.. Accuracy: 0.147\n",
            "Epoch 1/35.. Training Loss: 2.309.. Validation Loss: 2.295.. Accuracy: 0.151\n",
            "Epoch 1/35.. Training Loss: 2.295.. Validation Loss: 2.294.. Accuracy: 0.159\n",
            "Epoch 1/35.. Training Loss: 2.299.. Validation Loss: 2.293.. Accuracy: 0.167\n",
            "Epoch 1/35.. Training Loss: 2.302.. Validation Loss: 2.292.. Accuracy: 0.174\n",
            "Epoch 1/35.. Training Loss: 2.296.. Validation Loss: 2.291.. Accuracy: 0.182\n",
            "Epoch 1/35.. Training Loss: 2.296.. Validation Loss: 2.290.. Accuracy: 0.190\n",
            "Epoch 1/35.. Training Loss: 2.292.. Validation Loss: 2.289.. Accuracy: 0.193\n",
            "Epoch 1/35.. Training Loss: 2.290.. Validation Loss: 2.287.. Accuracy: 0.197\n",
            "Epoch 1/35.. Training Loss: 2.296.. Validation Loss: 2.286.. Accuracy: 0.202\n",
            "Epoch 1/35.. Training Loss: 2.279.. Validation Loss: 2.285.. Accuracy: 0.207\n",
            "Epoch 1/35.. Training Loss: 2.290.. Validation Loss: 2.284.. Accuracy: 0.214\n",
            "Epoch 1/35.. Training Loss: 2.287.. Validation Loss: 2.283.. Accuracy: 0.224\n",
            "Epoch 1/35.. Training Loss: 2.289.. Validation Loss: 2.282.. Accuracy: 0.234\n",
            "Epoch 1/35.. Training Loss: 2.285.. Validation Loss: 2.281.. Accuracy: 0.244\n",
            "Epoch 1/35.. Training Loss: 2.291.. Validation Loss: 2.279.. Accuracy: 0.255\n",
            "Epoch 1/35.. Training Loss: 2.284.. Validation Loss: 2.278.. Accuracy: 0.263\n",
            "Epoch 1/35.. Training Loss: 2.280.. Validation Loss: 2.276.. Accuracy: 0.267\n",
            "Epoch 1/35.. Training Loss: 2.282.. Validation Loss: 2.275.. Accuracy: 0.270\n",
            "Epoch 1/35.. Training Loss: 2.276.. Validation Loss: 2.273.. Accuracy: 0.272\n",
            "Epoch 1/35.. Training Loss: 2.283.. Validation Loss: 2.272.. Accuracy: 0.273\n",
            "Epoch 1/35.. Training Loss: 2.274.. Validation Loss: 2.270.. Accuracy: 0.272\n",
            "Epoch 1/35.. Training Loss: 2.272.. Validation Loss: 2.269.. Accuracy: 0.273\n",
            "Epoch 1/35.. Training Loss: 2.278.. Validation Loss: 2.267.. Accuracy: 0.274\n",
            "Epoch 1/35.. Training Loss: 2.282.. Validation Loss: 2.265.. Accuracy: 0.271\n",
            "Epoch 1/35.. Training Loss: 2.263.. Validation Loss: 2.264.. Accuracy: 0.269\n",
            "Epoch 1/35.. Training Loss: 2.274.. Validation Loss: 2.262.. Accuracy: 0.266\n",
            "Epoch 1/35.. Training Loss: 2.277.. Validation Loss: 2.260.. Accuracy: 0.266\n",
            "Epoch 1/35.. Training Loss: 2.267.. Validation Loss: 2.258.. Accuracy: 0.269\n",
            "Epoch 1/35.. Training Loss: 2.263.. Validation Loss: 2.256.. Accuracy: 0.274\n",
            "Epoch 1/35.. Training Loss: 2.266.. Validation Loss: 2.254.. Accuracy: 0.277\n",
            "Epoch 1/35.. Training Loss: 2.256.. Validation Loss: 2.251.. Accuracy: 0.279\n",
            "Epoch 1/35.. Training Loss: 2.259.. Validation Loss: 2.249.. Accuracy: 0.289\n",
            "Epoch 1/35.. Training Loss: 2.257.. Validation Loss: 2.246.. Accuracy: 0.300\n",
            "Epoch 1/35.. Training Loss: 2.267.. Validation Loss: 2.244.. Accuracy: 0.309\n",
            "Epoch 1/35.. Training Loss: 2.257.. Validation Loss: 2.241.. Accuracy: 0.312\n",
            "Epoch 1/35.. Training Loss: 2.254.. Validation Loss: 2.238.. Accuracy: 0.314\n",
            "Epoch 1/35.. Training Loss: 2.250.. Validation Loss: 2.236.. Accuracy: 0.322\n",
            "Epoch 1/35.. Training Loss: 2.246.. Validation Loss: 2.233.. Accuracy: 0.328\n",
            "Epoch 1/35.. Training Loss: 2.247.. Validation Loss: 2.230.. Accuracy: 0.334\n",
            "Epoch 1/35.. Training Loss: 2.247.. Validation Loss: 2.226.. Accuracy: 0.344\n",
            "Epoch 1/35.. Training Loss: 2.239.. Validation Loss: 2.223.. Accuracy: 0.349\n",
            "Epoch 1/35.. Training Loss: 2.244.. Validation Loss: 2.220.. Accuracy: 0.363\n",
            "Epoch 1/35.. Training Loss: 2.244.. Validation Loss: 2.216.. Accuracy: 0.376\n",
            "Epoch 1/35.. Training Loss: 2.223.. Validation Loss: 2.213.. Accuracy: 0.383\n",
            "Epoch 1/35.. Training Loss: 2.225.. Validation Loss: 2.208.. Accuracy: 0.383\n",
            "Epoch 1/35.. Training Loss: 2.236.. Validation Loss: 2.204.. Accuracy: 0.390\n",
            "Epoch 1/35.. Training Loss: 2.227.. Validation Loss: 2.201.. Accuracy: 0.400\n",
            "Epoch 1/35.. Training Loss: 2.234.. Validation Loss: 2.197.. Accuracy: 0.415\n",
            "Epoch 1/35.. Training Loss: 2.216.. Validation Loss: 2.193.. Accuracy: 0.426\n",
            "Epoch 1/35.. Training Loss: 2.221.. Validation Loss: 2.188.. Accuracy: 0.431\n",
            "Epoch 1/35.. Training Loss: 2.215.. Validation Loss: 2.183.. Accuracy: 0.437\n",
            "Epoch 1/35.. Training Loss: 2.201.. Validation Loss: 2.178.. Accuracy: 0.440\n",
            "Epoch 1/35.. Training Loss: 2.211.. Validation Loss: 2.173.. Accuracy: 0.444\n",
            "Epoch 1/35.. Training Loss: 2.198.. Validation Loss: 2.168.. Accuracy: 0.446\n",
            "Epoch 1/35.. Training Loss: 2.200.. Validation Loss: 2.162.. Accuracy: 0.449\n",
            "Epoch 1/35.. Training Loss: 2.186.. Validation Loss: 2.156.. Accuracy: 0.450\n",
            "Epoch 1/35.. Training Loss: 2.184.. Validation Loss: 2.149.. Accuracy: 0.448\n",
            "Epoch 1/35.. Training Loss: 2.176.. Validation Loss: 2.143.. Accuracy: 0.446\n",
            "Epoch 1/35.. Training Loss: 2.182.. Validation Loss: 2.136.. Accuracy: 0.451\n",
            "Epoch 1/35.. Training Loss: 2.148.. Validation Loss: 2.128.. Accuracy: 0.446\n",
            "Epoch 1/35.. Training Loss: 2.155.. Validation Loss: 2.119.. Accuracy: 0.441\n",
            "Epoch 1/35.. Training Loss: 2.169.. Validation Loss: 2.111.. Accuracy: 0.442\n",
            "Epoch 1/35.. Training Loss: 2.146.. Validation Loss: 2.102.. Accuracy: 0.442\n",
            "Epoch 1/35.. Training Loss: 2.159.. Validation Loss: 2.093.. Accuracy: 0.447\n",
            "Epoch 1/35.. Training Loss: 2.141.. Validation Loss: 2.084.. Accuracy: 0.460\n",
            "Epoch 1/35.. Training Loss: 2.132.. Validation Loss: 2.074.. Accuracy: 0.473\n",
            "Epoch 1/35.. Training Loss: 2.117.. Validation Loss: 2.064.. Accuracy: 0.487\n",
            "Epoch 1/35.. Training Loss: 2.127.. Validation Loss: 2.053.. Accuracy: 0.504\n",
            "Epoch 1/35.. Training Loss: 2.108.. Validation Loss: 2.042.. Accuracy: 0.528\n",
            "Epoch 1/35.. Training Loss: 2.096.. Validation Loss: 2.030.. Accuracy: 0.549\n",
            "Epoch 1/35.. Training Loss: 2.099.. Validation Loss: 2.018.. Accuracy: 0.561\n",
            "Epoch 1/35.. Training Loss: 2.078.. Validation Loss: 2.004.. Accuracy: 0.567\n",
            "Epoch 1/35.. Training Loss: 2.084.. Validation Loss: 1.991.. Accuracy: 0.568\n",
            "Epoch 1/35.. Training Loss: 2.087.. Validation Loss: 1.977.. Accuracy: 0.580\n",
            "Epoch 1/35.. Training Loss: 2.063.. Validation Loss: 1.963.. Accuracy: 0.595\n",
            "Epoch 1/35.. Training Loss: 2.041.. Validation Loss: 1.947.. Accuracy: 0.606\n",
            "Epoch 1/35.. Training Loss: 2.044.. Validation Loss: 1.931.. Accuracy: 0.617\n",
            "Epoch 1/35.. Training Loss: 2.018.. Validation Loss: 1.914.. Accuracy: 0.626\n",
            "Epoch 1/35.. Training Loss: 1.980.. Validation Loss: 1.896.. Accuracy: 0.632\n",
            "Epoch 1/35.. Training Loss: 1.977.. Validation Loss: 1.877.. Accuracy: 0.636\n",
            "Epoch 1/35.. Training Loss: 1.970.. Validation Loss: 1.857.. Accuracy: 0.643\n",
            "Epoch 1/35.. Training Loss: 1.944.. Validation Loss: 1.837.. Accuracy: 0.644\n",
            "Epoch 1/35.. Training Loss: 1.956.. Validation Loss: 1.815.. Accuracy: 0.647\n",
            "Epoch 1/35.. Training Loss: 1.959.. Validation Loss: 1.795.. Accuracy: 0.651\n",
            "Epoch 2/35.. Training Loss: 1.876.. Validation Loss: 1.772.. Accuracy: 0.659\n",
            "Epoch 2/35.. Training Loss: 1.862.. Validation Loss: 1.748.. Accuracy: 0.670\n",
            "Epoch 2/35.. Training Loss: 1.898.. Validation Loss: 1.723.. Accuracy: 0.689\n",
            "Epoch 2/35.. Training Loss: 1.832.. Validation Loss: 1.698.. Accuracy: 0.699\n",
            "Epoch 2/35.. Training Loss: 1.867.. Validation Loss: 1.673.. Accuracy: 0.702\n",
            "Epoch 2/35.. Training Loss: 1.821.. Validation Loss: 1.648.. Accuracy: 0.703\n",
            "Epoch 2/35.. Training Loss: 1.800.. Validation Loss: 1.622.. Accuracy: 0.704\n",
            "Epoch 2/35.. Training Loss: 1.809.. Validation Loss: 1.599.. Accuracy: 0.709\n",
            "Epoch 2/35.. Training Loss: 1.748.. Validation Loss: 1.573.. Accuracy: 0.721\n",
            "Epoch 2/35.. Training Loss: 1.811.. Validation Loss: 1.549.. Accuracy: 0.738\n",
            "Epoch 2/35.. Training Loss: 1.732.. Validation Loss: 1.523.. Accuracy: 0.747\n",
            "Epoch 2/35.. Training Loss: 1.755.. Validation Loss: 1.498.. Accuracy: 0.754\n",
            "Epoch 2/35.. Training Loss: 1.638.. Validation Loss: 1.471.. Accuracy: 0.756\n",
            "Epoch 2/35.. Training Loss: 1.666.. Validation Loss: 1.442.. Accuracy: 0.756\n",
            "Epoch 2/35.. Training Loss: 1.632.. Validation Loss: 1.414.. Accuracy: 0.753\n",
            "Epoch 2/35.. Training Loss: 1.663.. Validation Loss: 1.389.. Accuracy: 0.752\n",
            "Epoch 2/35.. Training Loss: 1.669.. Validation Loss: 1.365.. Accuracy: 0.752\n",
            "Epoch 2/35.. Training Loss: 1.614.. Validation Loss: 1.344.. Accuracy: 0.758\n",
            "Epoch 2/35.. Training Loss: 1.549.. Validation Loss: 1.318.. Accuracy: 0.764\n",
            "Epoch 2/35.. Training Loss: 1.561.. Validation Loss: 1.291.. Accuracy: 0.768\n",
            "Epoch 2/35.. Training Loss: 1.513.. Validation Loss: 1.264.. Accuracy: 0.766\n",
            "Epoch 2/35.. Training Loss: 1.520.. Validation Loss: 1.237.. Accuracy: 0.766\n",
            "Epoch 2/35.. Training Loss: 1.488.. Validation Loss: 1.209.. Accuracy: 0.765\n",
            "Epoch 2/35.. Training Loss: 1.501.. Validation Loss: 1.183.. Accuracy: 0.768\n",
            "Epoch 2/35.. Training Loss: 1.450.. Validation Loss: 1.161.. Accuracy: 0.778\n",
            "Epoch 2/35.. Training Loss: 1.455.. Validation Loss: 1.140.. Accuracy: 0.786\n",
            "Epoch 2/35.. Training Loss: 1.428.. Validation Loss: 1.121.. Accuracy: 0.797\n",
            "Epoch 2/35.. Training Loss: 1.402.. Validation Loss: 1.100.. Accuracy: 0.800\n",
            "Epoch 2/35.. Training Loss: 1.426.. Validation Loss: 1.080.. Accuracy: 0.801\n",
            "Epoch 2/35.. Training Loss: 1.417.. Validation Loss: 1.060.. Accuracy: 0.803\n",
            "Epoch 2/35.. Training Loss: 1.347.. Validation Loss: 1.039.. Accuracy: 0.802\n",
            "Epoch 2/35.. Training Loss: 1.370.. Validation Loss: 1.019.. Accuracy: 0.800\n",
            "Epoch 2/35.. Training Loss: 1.347.. Validation Loss: 1.002.. Accuracy: 0.798\n",
            "Epoch 2/35.. Training Loss: 1.335.. Validation Loss: 0.987.. Accuracy: 0.797\n",
            "Epoch 2/35.. Training Loss: 1.312.. Validation Loss: 0.971.. Accuracy: 0.796\n",
            "Epoch 2/35.. Training Loss: 1.348.. Validation Loss: 0.955.. Accuracy: 0.802\n",
            "Epoch 2/35.. Training Loss: 1.271.. Validation Loss: 0.939.. Accuracy: 0.808\n",
            "Epoch 2/35.. Training Loss: 1.259.. Validation Loss: 0.922.. Accuracy: 0.811\n",
            "Epoch 2/35.. Training Loss: 1.284.. Validation Loss: 0.906.. Accuracy: 0.811\n",
            "Epoch 2/35.. Training Loss: 1.218.. Validation Loss: 0.892.. Accuracy: 0.814\n",
            "Epoch 2/35.. Training Loss: 1.167.. Validation Loss: 0.876.. Accuracy: 0.815\n",
            "Epoch 2/35.. Training Loss: 1.211.. Validation Loss: 0.860.. Accuracy: 0.816\n",
            "Epoch 2/35.. Training Loss: 1.279.. Validation Loss: 0.850.. Accuracy: 0.815\n",
            "Epoch 2/35.. Training Loss: 1.218.. Validation Loss: 0.841.. Accuracy: 0.813\n",
            "Epoch 2/35.. Training Loss: 1.205.. Validation Loss: 0.832.. Accuracy: 0.808\n",
            "Epoch 2/35.. Training Loss: 1.211.. Validation Loss: 0.823.. Accuracy: 0.809\n",
            "Epoch 2/35.. Training Loss: 1.101.. Validation Loss: 0.812.. Accuracy: 0.814\n",
            "Epoch 2/35.. Training Loss: 1.218.. Validation Loss: 0.799.. Accuracy: 0.817\n",
            "Epoch 2/35.. Training Loss: 1.105.. Validation Loss: 0.787.. Accuracy: 0.824\n",
            "Epoch 2/35.. Training Loss: 1.255.. Validation Loss: 0.776.. Accuracy: 0.831\n",
            "Epoch 2/35.. Training Loss: 1.188.. Validation Loss: 0.766.. Accuracy: 0.834\n",
            "Epoch 2/35.. Training Loss: 1.143.. Validation Loss: 0.755.. Accuracy: 0.834\n",
            "Epoch 2/35.. Training Loss: 1.121.. Validation Loss: 0.743.. Accuracy: 0.835\n",
            "Epoch 2/35.. Training Loss: 1.171.. Validation Loss: 0.734.. Accuracy: 0.835\n",
            "Epoch 2/35.. Training Loss: 1.102.. Validation Loss: 0.726.. Accuracy: 0.838\n",
            "Epoch 2/35.. Training Loss: 1.153.. Validation Loss: 0.720.. Accuracy: 0.836\n",
            "Epoch 2/35.. Training Loss: 1.071.. Validation Loss: 0.712.. Accuracy: 0.835\n",
            "Epoch 2/35.. Training Loss: 1.110.. Validation Loss: 0.704.. Accuracy: 0.837\n",
            "Epoch 2/35.. Training Loss: 1.077.. Validation Loss: 0.696.. Accuracy: 0.839\n",
            "Epoch 2/35.. Training Loss: 1.155.. Validation Loss: 0.689.. Accuracy: 0.839\n",
            "Epoch 2/35.. Training Loss: 1.046.. Validation Loss: 0.685.. Accuracy: 0.839\n",
            "Epoch 2/35.. Training Loss: 1.047.. Validation Loss: 0.677.. Accuracy: 0.840\n",
            "Epoch 2/35.. Training Loss: 1.026.. Validation Loss: 0.666.. Accuracy: 0.839\n",
            "Epoch 2/35.. Training Loss: 1.101.. Validation Loss: 0.658.. Accuracy: 0.842\n",
            "Epoch 2/35.. Training Loss: 1.005.. Validation Loss: 0.650.. Accuracy: 0.844\n",
            "Epoch 2/35.. Training Loss: 0.983.. Validation Loss: 0.641.. Accuracy: 0.847\n",
            "Epoch 2/35.. Training Loss: 1.013.. Validation Loss: 0.632.. Accuracy: 0.847\n",
            "Epoch 2/35.. Training Loss: 1.007.. Validation Loss: 0.624.. Accuracy: 0.846\n",
            "Epoch 2/35.. Training Loss: 0.973.. Validation Loss: 0.619.. Accuracy: 0.848\n",
            "Epoch 2/35.. Training Loss: 1.105.. Validation Loss: 0.615.. Accuracy: 0.849\n",
            "Epoch 2/35.. Training Loss: 0.967.. Validation Loss: 0.614.. Accuracy: 0.849\n",
            "Epoch 2/35.. Training Loss: 1.014.. Validation Loss: 0.613.. Accuracy: 0.851\n",
            "Epoch 2/35.. Training Loss: 0.985.. Validation Loss: 0.610.. Accuracy: 0.852\n",
            "Epoch 2/35.. Training Loss: 0.957.. Validation Loss: 0.604.. Accuracy: 0.856\n",
            "Epoch 2/35.. Training Loss: 1.051.. Validation Loss: 0.599.. Accuracy: 0.857\n",
            "Epoch 2/35.. Training Loss: 1.002.. Validation Loss: 0.595.. Accuracy: 0.857\n",
            "Epoch 2/35.. Training Loss: 0.989.. Validation Loss: 0.591.. Accuracy: 0.857\n",
            "Epoch 2/35.. Training Loss: 0.958.. Validation Loss: 0.589.. Accuracy: 0.855\n",
            "Epoch 2/35.. Training Loss: 0.937.. Validation Loss: 0.583.. Accuracy: 0.852\n",
            "Epoch 2/35.. Training Loss: 0.943.. Validation Loss: 0.573.. Accuracy: 0.856\n",
            "Epoch 2/35.. Training Loss: 0.982.. Validation Loss: 0.566.. Accuracy: 0.857\n",
            "Epoch 2/35.. Training Loss: 0.954.. Validation Loss: 0.563.. Accuracy: 0.857\n",
            "Epoch 2/35.. Training Loss: 0.990.. Validation Loss: 0.560.. Accuracy: 0.860\n",
            "Epoch 2/35.. Training Loss: 1.061.. Validation Loss: 0.559.. Accuracy: 0.862\n",
            "Epoch 2/35.. Training Loss: 0.890.. Validation Loss: 0.556.. Accuracy: 0.863\n",
            "Epoch 2/35.. Training Loss: 0.892.. Validation Loss: 0.550.. Accuracy: 0.864\n",
            "Epoch 2/35.. Training Loss: 0.860.. Validation Loss: 0.544.. Accuracy: 0.863\n",
            "Epoch 2/35.. Training Loss: 0.898.. Validation Loss: 0.537.. Accuracy: 0.863\n",
            "Epoch 2/35.. Training Loss: 0.858.. Validation Loss: 0.530.. Accuracy: 0.864\n",
            "Epoch 2/35.. Training Loss: 0.860.. Validation Loss: 0.523.. Accuracy: 0.865\n",
            "Epoch 2/35.. Training Loss: 0.952.. Validation Loss: 0.519.. Accuracy: 0.866\n",
            "Epoch 2/35.. Training Loss: 0.848.. Validation Loss: 0.517.. Accuracy: 0.866\n",
            "Epoch 2/35.. Training Loss: 0.961.. Validation Loss: 0.517.. Accuracy: 0.865\n",
            "Epoch 2/35.. Training Loss: 0.860.. Validation Loss: 0.517.. Accuracy: 0.864\n",
            "Epoch 3/35.. Training Loss: 0.911.. Validation Loss: 0.515.. Accuracy: 0.865\n",
            "Epoch 3/35.. Training Loss: 0.844.. Validation Loss: 0.512.. Accuracy: 0.868\n",
            "Epoch 3/35.. Training Loss: 0.899.. Validation Loss: 0.507.. Accuracy: 0.871\n",
            "Epoch 3/35.. Training Loss: 0.817.. Validation Loss: 0.503.. Accuracy: 0.870\n",
            "Epoch 3/35.. Training Loss: 0.907.. Validation Loss: 0.499.. Accuracy: 0.873\n",
            "Epoch 3/35.. Training Loss: 0.871.. Validation Loss: 0.501.. Accuracy: 0.873\n",
            "Epoch 3/35.. Training Loss: 0.804.. Validation Loss: 0.497.. Accuracy: 0.873\n",
            "Epoch 3/35.. Training Loss: 0.846.. Validation Loss: 0.490.. Accuracy: 0.874\n",
            "Epoch 3/35.. Training Loss: 0.903.. Validation Loss: 0.488.. Accuracy: 0.875\n",
            "Epoch 3/35.. Training Loss: 0.894.. Validation Loss: 0.488.. Accuracy: 0.874\n",
            "Epoch 3/35.. Training Loss: 0.877.. Validation Loss: 0.488.. Accuracy: 0.873\n",
            "Epoch 3/35.. Training Loss: 0.851.. Validation Loss: 0.486.. Accuracy: 0.873\n",
            "Epoch 3/35.. Training Loss: 0.843.. Validation Loss: 0.479.. Accuracy: 0.876\n",
            "Epoch 3/35.. Training Loss: 0.928.. Validation Loss: 0.480.. Accuracy: 0.876\n",
            "Epoch 3/35.. Training Loss: 0.835.. Validation Loss: 0.479.. Accuracy: 0.878\n",
            "Epoch 3/35.. Training Loss: 0.806.. Validation Loss: 0.478.. Accuracy: 0.877\n",
            "Epoch 3/35.. Training Loss: 0.824.. Validation Loss: 0.474.. Accuracy: 0.878\n",
            "Epoch 3/35.. Training Loss: 0.887.. Validation Loss: 0.470.. Accuracy: 0.876\n",
            "Epoch 3/35.. Training Loss: 0.827.. Validation Loss: 0.468.. Accuracy: 0.877\n",
            "Epoch 3/35.. Training Loss: 0.829.. Validation Loss: 0.462.. Accuracy: 0.880\n",
            "Epoch 3/35.. Training Loss: 0.836.. Validation Loss: 0.456.. Accuracy: 0.881\n",
            "Epoch 3/35.. Training Loss: 0.779.. Validation Loss: 0.453.. Accuracy: 0.882\n",
            "Epoch 3/35.. Training Loss: 0.830.. Validation Loss: 0.452.. Accuracy: 0.884\n",
            "Epoch 3/35.. Training Loss: 0.799.. Validation Loss: 0.450.. Accuracy: 0.883\n",
            "Epoch 3/35.. Training Loss: 0.745.. Validation Loss: 0.449.. Accuracy: 0.883\n",
            "Epoch 3/35.. Training Loss: 0.799.. Validation Loss: 0.446.. Accuracy: 0.883\n",
            "Epoch 3/35.. Training Loss: 0.746.. Validation Loss: 0.441.. Accuracy: 0.884\n",
            "Epoch 3/35.. Training Loss: 0.818.. Validation Loss: 0.437.. Accuracy: 0.883\n",
            "Epoch 3/35.. Training Loss: 0.859.. Validation Loss: 0.437.. Accuracy: 0.882\n",
            "Epoch 3/35.. Training Loss: 0.753.. Validation Loss: 0.437.. Accuracy: 0.878\n",
            "Epoch 3/35.. Training Loss: 0.782.. Validation Loss: 0.436.. Accuracy: 0.877\n",
            "Epoch 3/35.. Training Loss: 0.805.. Validation Loss: 0.433.. Accuracy: 0.878\n",
            "Epoch 3/35.. Training Loss: 0.800.. Validation Loss: 0.427.. Accuracy: 0.882\n",
            "Epoch 3/35.. Training Loss: 0.818.. Validation Loss: 0.425.. Accuracy: 0.884\n",
            "Epoch 3/35.. Training Loss: 0.799.. Validation Loss: 0.424.. Accuracy: 0.885\n",
            "Epoch 3/35.. Training Loss: 0.789.. Validation Loss: 0.422.. Accuracy: 0.886\n",
            "Epoch 3/35.. Training Loss: 0.856.. Validation Loss: 0.422.. Accuracy: 0.889\n",
            "Epoch 3/35.. Training Loss: 0.763.. Validation Loss: 0.425.. Accuracy: 0.888\n",
            "Epoch 3/35.. Training Loss: 0.766.. Validation Loss: 0.424.. Accuracy: 0.888\n",
            "Epoch 3/35.. Training Loss: 0.734.. Validation Loss: 0.423.. Accuracy: 0.888\n",
            "Epoch 3/35.. Training Loss: 0.773.. Validation Loss: 0.422.. Accuracy: 0.887\n",
            "Epoch 3/35.. Training Loss: 0.646.. Validation Loss: 0.421.. Accuracy: 0.885\n",
            "Epoch 3/35.. Training Loss: 0.744.. Validation Loss: 0.416.. Accuracy: 0.886\n",
            "Epoch 3/35.. Training Loss: 0.771.. Validation Loss: 0.411.. Accuracy: 0.886\n",
            "Epoch 3/35.. Training Loss: 0.777.. Validation Loss: 0.406.. Accuracy: 0.889\n",
            "Epoch 3/35.. Training Loss: 0.776.. Validation Loss: 0.404.. Accuracy: 0.892\n",
            "Epoch 3/35.. Training Loss: 0.793.. Validation Loss: 0.401.. Accuracy: 0.892\n",
            "Epoch 3/35.. Training Loss: 0.738.. Validation Loss: 0.401.. Accuracy: 0.892\n",
            "Epoch 3/35.. Training Loss: 0.733.. Validation Loss: 0.399.. Accuracy: 0.891\n",
            "Epoch 3/35.. Training Loss: 0.792.. Validation Loss: 0.399.. Accuracy: 0.891\n",
            "Epoch 3/35.. Training Loss: 0.793.. Validation Loss: 0.400.. Accuracy: 0.890\n",
            "Epoch 3/35.. Training Loss: 0.661.. Validation Loss: 0.399.. Accuracy: 0.888\n",
            "Epoch 3/35.. Training Loss: 0.647.. Validation Loss: 0.399.. Accuracy: 0.884\n",
            "Epoch 3/35.. Training Loss: 0.734.. Validation Loss: 0.395.. Accuracy: 0.884\n",
            "Epoch 3/35.. Training Loss: 0.645.. Validation Loss: 0.388.. Accuracy: 0.888\n",
            "Epoch 3/35.. Training Loss: 0.662.. Validation Loss: 0.382.. Accuracy: 0.894\n",
            "Epoch 3/35.. Training Loss: 0.699.. Validation Loss: 0.379.. Accuracy: 0.897\n",
            "Epoch 3/35.. Training Loss: 0.793.. Validation Loss: 0.381.. Accuracy: 0.895\n",
            "Epoch 3/35.. Training Loss: 0.769.. Validation Loss: 0.385.. Accuracy: 0.895\n",
            "Epoch 3/35.. Training Loss: 0.729.. Validation Loss: 0.384.. Accuracy: 0.897\n",
            "Epoch 3/35.. Training Loss: 0.678.. Validation Loss: 0.380.. Accuracy: 0.898\n",
            "Epoch 3/35.. Training Loss: 0.672.. Validation Loss: 0.375.. Accuracy: 0.899\n",
            "Epoch 3/35.. Training Loss: 0.680.. Validation Loss: 0.371.. Accuracy: 0.900\n",
            "Epoch 3/35.. Training Loss: 0.709.. Validation Loss: 0.369.. Accuracy: 0.899\n",
            "Epoch 3/35.. Training Loss: 0.640.. Validation Loss: 0.367.. Accuracy: 0.897\n",
            "Epoch 3/35.. Training Loss: 0.686.. Validation Loss: 0.363.. Accuracy: 0.899\n",
            "Epoch 3/35.. Training Loss: 0.750.. Validation Loss: 0.364.. Accuracy: 0.900\n",
            "Epoch 3/35.. Training Loss: 0.666.. Validation Loss: 0.363.. Accuracy: 0.900\n",
            "Epoch 3/35.. Training Loss: 0.746.. Validation Loss: 0.364.. Accuracy: 0.901\n",
            "Epoch 3/35.. Training Loss: 0.722.. Validation Loss: 0.364.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.714.. Validation Loss: 0.364.. Accuracy: 0.902\n",
            "Epoch 3/35.. Training Loss: 0.730.. Validation Loss: 0.364.. Accuracy: 0.902\n",
            "Epoch 3/35.. Training Loss: 0.659.. Validation Loss: 0.362.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.727.. Validation Loss: 0.363.. Accuracy: 0.902\n",
            "Epoch 3/35.. Training Loss: 0.645.. Validation Loss: 0.362.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.688.. Validation Loss: 0.360.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.693.. Validation Loss: 0.357.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.710.. Validation Loss: 0.357.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.643.. Validation Loss: 0.355.. Accuracy: 0.905\n",
            "Epoch 3/35.. Training Loss: 0.725.. Validation Loss: 0.352.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.637.. Validation Loss: 0.350.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.676.. Validation Loss: 0.351.. Accuracy: 0.903\n",
            "Epoch 3/35.. Training Loss: 0.704.. Validation Loss: 0.348.. Accuracy: 0.904\n",
            "Epoch 3/35.. Training Loss: 0.664.. Validation Loss: 0.346.. Accuracy: 0.905\n",
            "Epoch 3/35.. Training Loss: 0.661.. Validation Loss: 0.345.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.667.. Validation Loss: 0.343.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.657.. Validation Loss: 0.343.. Accuracy: 0.905\n",
            "Epoch 3/35.. Training Loss: 0.661.. Validation Loss: 0.343.. Accuracy: 0.904\n",
            "Epoch 3/35.. Training Loss: 0.665.. Validation Loss: 0.343.. Accuracy: 0.905\n",
            "Epoch 3/35.. Training Loss: 0.764.. Validation Loss: 0.343.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.656.. Validation Loss: 0.344.. Accuracy: 0.905\n",
            "Epoch 3/35.. Training Loss: 0.667.. Validation Loss: 0.340.. Accuracy: 0.906\n",
            "Epoch 3/35.. Training Loss: 0.696.. Validation Loss: 0.339.. Accuracy: 0.908\n",
            "Epoch 4/35.. Training Loss: 0.629.. Validation Loss: 0.339.. Accuracy: 0.908\n",
            "Epoch 4/35.. Training Loss: 0.710.. Validation Loss: 0.341.. Accuracy: 0.908\n",
            "Epoch 4/35.. Training Loss: 0.622.. Validation Loss: 0.338.. Accuracy: 0.908\n",
            "Epoch 4/35.. Training Loss: 0.663.. Validation Loss: 0.332.. Accuracy: 0.909\n",
            "Epoch 4/35.. Training Loss: 0.593.. Validation Loss: 0.328.. Accuracy: 0.909\n",
            "Epoch 4/35.. Training Loss: 0.658.. Validation Loss: 0.326.. Accuracy: 0.910\n",
            "Epoch 4/35.. Training Loss: 0.619.. Validation Loss: 0.325.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.667.. Validation Loss: 0.325.. Accuracy: 0.911\n",
            "Epoch 4/35.. Training Loss: 0.575.. Validation Loss: 0.324.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.645.. Validation Loss: 0.324.. Accuracy: 0.911\n",
            "Epoch 4/35.. Training Loss: 0.685.. Validation Loss: 0.325.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.696.. Validation Loss: 0.326.. Accuracy: 0.911\n",
            "Epoch 4/35.. Training Loss: 0.671.. Validation Loss: 0.325.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.613.. Validation Loss: 0.323.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.679.. Validation Loss: 0.322.. Accuracy: 0.911\n",
            "Epoch 4/35.. Training Loss: 0.635.. Validation Loss: 0.320.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.596.. Validation Loss: 0.318.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.628.. Validation Loss: 0.317.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.618.. Validation Loss: 0.317.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.670.. Validation Loss: 0.314.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.666.. Validation Loss: 0.313.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.592.. Validation Loss: 0.313.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.629.. Validation Loss: 0.314.. Accuracy: 0.913\n",
            "Epoch 4/35.. Training Loss: 0.648.. Validation Loss: 0.316.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.649.. Validation Loss: 0.317.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.589.. Validation Loss: 0.318.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.632.. Validation Loss: 0.315.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.627.. Validation Loss: 0.311.. Accuracy: 0.916\n",
            "Epoch 4/35.. Training Loss: 0.625.. Validation Loss: 0.308.. Accuracy: 0.916\n",
            "Epoch 4/35.. Training Loss: 0.592.. Validation Loss: 0.307.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.705.. Validation Loss: 0.307.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.688.. Validation Loss: 0.309.. Accuracy: 0.912\n",
            "Epoch 4/35.. Training Loss: 0.622.. Validation Loss: 0.309.. Accuracy: 0.914\n",
            "Epoch 4/35.. Training Loss: 0.624.. Validation Loss: 0.305.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.618.. Validation Loss: 0.302.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.599.. Validation Loss: 0.302.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.521.. Validation Loss: 0.300.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.613.. Validation Loss: 0.298.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.641.. Validation Loss: 0.297.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.605.. Validation Loss: 0.297.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.560.. Validation Loss: 0.297.. Accuracy: 0.915\n",
            "Epoch 4/35.. Training Loss: 0.640.. Validation Loss: 0.295.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.620.. Validation Loss: 0.295.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.550.. Validation Loss: 0.294.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.634.. Validation Loss: 0.293.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.644.. Validation Loss: 0.295.. Accuracy: 0.919\n",
            "Epoch 4/35.. Training Loss: 0.617.. Validation Loss: 0.293.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.570.. Validation Loss: 0.292.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.622.. Validation Loss: 0.290.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.528.. Validation Loss: 0.289.. Accuracy: 0.916\n",
            "Epoch 4/35.. Training Loss: 0.544.. Validation Loss: 0.287.. Accuracy: 0.917\n",
            "Epoch 4/35.. Training Loss: 0.528.. Validation Loss: 0.288.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.573.. Validation Loss: 0.288.. Accuracy: 0.918\n",
            "Epoch 4/35.. Training Loss: 0.641.. Validation Loss: 0.287.. Accuracy: 0.919\n",
            "Epoch 4/35.. Training Loss: 0.654.. Validation Loss: 0.287.. Accuracy: 0.919\n",
            "Epoch 4/35.. Training Loss: 0.612.. Validation Loss: 0.286.. Accuracy: 0.921\n",
            "Epoch 4/35.. Training Loss: 0.525.. Validation Loss: 0.288.. Accuracy: 0.921\n",
            "Epoch 4/35.. Training Loss: 0.603.. Validation Loss: 0.287.. Accuracy: 0.921\n",
            "Epoch 4/35.. Training Loss: 0.606.. Validation Loss: 0.283.. Accuracy: 0.922\n",
            "Epoch 4/35.. Training Loss: 0.552.. Validation Loss: 0.281.. Accuracy: 0.922\n",
            "Epoch 4/35.. Training Loss: 0.542.. Validation Loss: 0.280.. Accuracy: 0.920\n",
            "Epoch 4/35.. Training Loss: 0.567.. Validation Loss: 0.278.. Accuracy: 0.921\n",
            "Epoch 4/35.. Training Loss: 0.569.. Validation Loss: 0.279.. Accuracy: 0.922\n",
            "Epoch 4/35.. Training Loss: 0.531.. Validation Loss: 0.280.. Accuracy: 0.922\n",
            "Epoch 4/35.. Training Loss: 0.599.. Validation Loss: 0.282.. Accuracy: 0.923\n",
            "Epoch 4/35.. Training Loss: 0.571.. Validation Loss: 0.282.. Accuracy: 0.922\n",
            "Epoch 4/35.. Training Loss: 0.616.. Validation Loss: 0.280.. Accuracy: 0.923\n",
            "Epoch 4/35.. Training Loss: 0.521.. Validation Loss: 0.277.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.534.. Validation Loss: 0.274.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.501.. Validation Loss: 0.273.. Accuracy: 0.923\n",
            "Epoch 4/35.. Training Loss: 0.614.. Validation Loss: 0.273.. Accuracy: 0.923\n",
            "Epoch 4/35.. Training Loss: 0.551.. Validation Loss: 0.270.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.576.. Validation Loss: 0.268.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.607.. Validation Loss: 0.269.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.615.. Validation Loss: 0.269.. Accuracy: 0.924\n",
            "Epoch 4/35.. Training Loss: 0.613.. Validation Loss: 0.270.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.627.. Validation Loss: 0.271.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.612.. Validation Loss: 0.271.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.508.. Validation Loss: 0.270.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.551.. Validation Loss: 0.268.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.537.. Validation Loss: 0.266.. Accuracy: 0.927\n",
            "Epoch 4/35.. Training Loss: 0.540.. Validation Loss: 0.265.. Accuracy: 0.927\n",
            "Epoch 4/35.. Training Loss: 0.605.. Validation Loss: 0.263.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.573.. Validation Loss: 0.262.. Accuracy: 0.927\n",
            "Epoch 4/35.. Training Loss: 0.521.. Validation Loss: 0.261.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.630.. Validation Loss: 0.260.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.552.. Validation Loss: 0.260.. Accuracy: 0.927\n",
            "Epoch 4/35.. Training Loss: 0.464.. Validation Loss: 0.260.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.489.. Validation Loss: 0.260.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.643.. Validation Loss: 0.262.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.531.. Validation Loss: 0.262.. Accuracy: 0.926\n",
            "Epoch 4/35.. Training Loss: 0.507.. Validation Loss: 0.260.. Accuracy: 0.925\n",
            "Epoch 4/35.. Training Loss: 0.591.. Validation Loss: 0.257.. Accuracy: 0.927\n",
            "Epoch 4/35.. Training Loss: 0.513.. Validation Loss: 0.257.. Accuracy: 0.926\n",
            "Epoch 5/35.. Training Loss: 0.524.. Validation Loss: 0.256.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.576.. Validation Loss: 0.256.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.533.. Validation Loss: 0.256.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.564.. Validation Loss: 0.256.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.470.. Validation Loss: 0.254.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.541.. Validation Loss: 0.252.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.557.. Validation Loss: 0.250.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.533.. Validation Loss: 0.249.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.554.. Validation Loss: 0.249.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.582.. Validation Loss: 0.250.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.538.. Validation Loss: 0.250.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.517.. Validation Loss: 0.251.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.532.. Validation Loss: 0.252.. Accuracy: 0.926\n",
            "Epoch 5/35.. Training Loss: 0.571.. Validation Loss: 0.253.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.585.. Validation Loss: 0.253.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.605.. Validation Loss: 0.251.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.607.. Validation Loss: 0.250.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.522.. Validation Loss: 0.250.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.530.. Validation Loss: 0.249.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.525.. Validation Loss: 0.248.. Accuracy: 0.929\n",
            "Epoch 5/35.. Training Loss: 0.611.. Validation Loss: 0.249.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.493.. Validation Loss: 0.248.. Accuracy: 0.927\n",
            "Epoch 5/35.. Training Loss: 0.476.. Validation Loss: 0.248.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.439.. Validation Loss: 0.245.. Accuracy: 0.928\n",
            "Epoch 5/35.. Training Loss: 0.494.. Validation Loss: 0.244.. Accuracy: 0.930\n",
            "Epoch 5/35.. Training Loss: 0.515.. Validation Loss: 0.244.. Accuracy: 0.930\n",
            "Epoch 5/35.. Training Loss: 0.501.. Validation Loss: 0.243.. Accuracy: 0.930\n",
            "Epoch 5/35.. Training Loss: 0.602.. Validation Loss: 0.243.. Accuracy: 0.930\n",
            "Epoch 5/35.. Training Loss: 0.541.. Validation Loss: 0.242.. Accuracy: 0.930\n",
            "Epoch 5/35.. Training Loss: 0.524.. Validation Loss: 0.241.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.549.. Validation Loss: 0.241.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.531.. Validation Loss: 0.241.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.497.. Validation Loss: 0.240.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.463.. Validation Loss: 0.238.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.467.. Validation Loss: 0.237.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.550.. Validation Loss: 0.237.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.528.. Validation Loss: 0.235.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.479.. Validation Loss: 0.234.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.520.. Validation Loss: 0.232.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.455.. Validation Loss: 0.232.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.505.. Validation Loss: 0.231.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.475.. Validation Loss: 0.231.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.492.. Validation Loss: 0.231.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.479.. Validation Loss: 0.230.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.519.. Validation Loss: 0.230.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.504.. Validation Loss: 0.229.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.478.. Validation Loss: 0.228.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.535.. Validation Loss: 0.226.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.502.. Validation Loss: 0.224.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.477.. Validation Loss: 0.223.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.488.. Validation Loss: 0.223.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.525.. Validation Loss: 0.223.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.520.. Validation Loss: 0.225.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.480.. Validation Loss: 0.225.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.508.. Validation Loss: 0.226.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.506.. Validation Loss: 0.226.. Accuracy: 0.931\n",
            "Epoch 5/35.. Training Loss: 0.489.. Validation Loss: 0.226.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.523.. Validation Loss: 0.225.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.465.. Validation Loss: 0.225.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.505.. Validation Loss: 0.225.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.482.. Validation Loss: 0.225.. Accuracy: 0.934\n",
            "Epoch 5/35.. Training Loss: 0.515.. Validation Loss: 0.226.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.517.. Validation Loss: 0.227.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.500.. Validation Loss: 0.226.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.512.. Validation Loss: 0.225.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.486.. Validation Loss: 0.225.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.442.. Validation Loss: 0.225.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.478.. Validation Loss: 0.225.. Accuracy: 0.932\n",
            "Epoch 5/35.. Training Loss: 0.531.. Validation Loss: 0.224.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.455.. Validation Loss: 0.221.. Accuracy: 0.933\n",
            "Epoch 5/35.. Training Loss: 0.429.. Validation Loss: 0.219.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.468.. Validation Loss: 0.219.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.521.. Validation Loss: 0.217.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.500.. Validation Loss: 0.217.. Accuracy: 0.937\n",
            "Epoch 5/35.. Training Loss: 0.527.. Validation Loss: 0.216.. Accuracy: 0.937\n",
            "Epoch 5/35.. Training Loss: 0.470.. Validation Loss: 0.217.. Accuracy: 0.937\n",
            "Epoch 5/35.. Training Loss: 0.485.. Validation Loss: 0.217.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.442.. Validation Loss: 0.217.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.444.. Validation Loss: 0.219.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.533.. Validation Loss: 0.219.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.455.. Validation Loss: 0.218.. Accuracy: 0.937\n",
            "Epoch 5/35.. Training Loss: 0.487.. Validation Loss: 0.219.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.472.. Validation Loss: 0.221.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.625.. Validation Loss: 0.219.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.527.. Validation Loss: 0.217.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.462.. Validation Loss: 0.216.. Accuracy: 0.935\n",
            "Epoch 5/35.. Training Loss: 0.500.. Validation Loss: 0.215.. Accuracy: 0.936\n",
            "Epoch 5/35.. Training Loss: 0.471.. Validation Loss: 0.213.. Accuracy: 0.937\n",
            "Epoch 5/35.. Training Loss: 0.514.. Validation Loss: 0.212.. Accuracy: 0.938\n",
            "Epoch 5/35.. Training Loss: 0.531.. Validation Loss: 0.211.. Accuracy: 0.938\n",
            "Epoch 5/35.. Training Loss: 0.464.. Validation Loss: 0.211.. Accuracy: 0.938\n",
            "Epoch 5/35.. Training Loss: 0.485.. Validation Loss: 0.211.. Accuracy: 0.938\n",
            "Epoch 5/35.. Training Loss: 0.406.. Validation Loss: 0.210.. Accuracy: 0.939\n",
            "Epoch 5/35.. Training Loss: 0.514.. Validation Loss: 0.209.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.449.. Validation Loss: 0.210.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.448.. Validation Loss: 0.209.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.378.. Validation Loss: 0.208.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.451.. Validation Loss: 0.207.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.421.. Validation Loss: 0.207.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.508.. Validation Loss: 0.208.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.474.. Validation Loss: 0.209.. Accuracy: 0.939\n",
            "Epoch 6/35.. Training Loss: 0.475.. Validation Loss: 0.208.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.524.. Validation Loss: 0.208.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.462.. Validation Loss: 0.209.. Accuracy: 0.939\n",
            "Epoch 6/35.. Training Loss: 0.475.. Validation Loss: 0.211.. Accuracy: 0.938\n",
            "Epoch 6/35.. Training Loss: 0.435.. Validation Loss: 0.209.. Accuracy: 0.939\n",
            "Epoch 6/35.. Training Loss: 0.463.. Validation Loss: 0.207.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.454.. Validation Loss: 0.206.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.422.. Validation Loss: 0.206.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.538.. Validation Loss: 0.206.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.446.. Validation Loss: 0.205.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.434.. Validation Loss: 0.205.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.495.. Validation Loss: 0.204.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.512.. Validation Loss: 0.204.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.471.. Validation Loss: 0.202.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.428.. Validation Loss: 0.201.. Accuracy: 0.939\n",
            "Epoch 6/35.. Training Loss: 0.527.. Validation Loss: 0.201.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.497.. Validation Loss: 0.201.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.429.. Validation Loss: 0.200.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.401.. Validation Loss: 0.200.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.444.. Validation Loss: 0.200.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.382.. Validation Loss: 0.200.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.450.. Validation Loss: 0.199.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.439.. Validation Loss: 0.198.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.509.. Validation Loss: 0.196.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.402.. Validation Loss: 0.197.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.448.. Validation Loss: 0.196.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.472.. Validation Loss: 0.195.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.383.. Validation Loss: 0.195.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.362.. Validation Loss: 0.196.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.445.. Validation Loss: 0.195.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.484.. Validation Loss: 0.195.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.462.. Validation Loss: 0.196.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.437.. Validation Loss: 0.196.. Accuracy: 0.940\n",
            "Epoch 6/35.. Training Loss: 0.556.. Validation Loss: 0.197.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.404.. Validation Loss: 0.196.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.477.. Validation Loss: 0.196.. Accuracy: 0.941\n",
            "Epoch 6/35.. Training Loss: 0.507.. Validation Loss: 0.196.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.412.. Validation Loss: 0.195.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.430.. Validation Loss: 0.195.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.481.. Validation Loss: 0.194.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.428.. Validation Loss: 0.192.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.445.. Validation Loss: 0.192.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.407.. Validation Loss: 0.191.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.427.. Validation Loss: 0.190.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.474.. Validation Loss: 0.191.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.486.. Validation Loss: 0.191.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.449.. Validation Loss: 0.191.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.446.. Validation Loss: 0.192.. Accuracy: 0.942\n",
            "Epoch 6/35.. Training Loss: 0.461.. Validation Loss: 0.191.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.477.. Validation Loss: 0.192.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.469.. Validation Loss: 0.192.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.473.. Validation Loss: 0.192.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.417.. Validation Loss: 0.191.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.447.. Validation Loss: 0.191.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.471.. Validation Loss: 0.192.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.455.. Validation Loss: 0.192.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.417.. Validation Loss: 0.191.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.506.. Validation Loss: 0.191.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.471.. Validation Loss: 0.191.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.392.. Validation Loss: 0.189.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.476.. Validation Loss: 0.188.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.391.. Validation Loss: 0.187.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.495.. Validation Loss: 0.187.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.397.. Validation Loss: 0.188.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.484.. Validation Loss: 0.187.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.444.. Validation Loss: 0.186.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.426.. Validation Loss: 0.186.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.396.. Validation Loss: 0.187.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.496.. Validation Loss: 0.188.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.450.. Validation Loss: 0.190.. Accuracy: 0.943\n",
            "Epoch 6/35.. Training Loss: 0.483.. Validation Loss: 0.188.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.453.. Validation Loss: 0.188.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.490.. Validation Loss: 0.187.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.394.. Validation Loss: 0.187.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.452.. Validation Loss: 0.186.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.400.. Validation Loss: 0.185.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.469.. Validation Loss: 0.184.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.448.. Validation Loss: 0.183.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.390.. Validation Loss: 0.183.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.352.. Validation Loss: 0.182.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.435.. Validation Loss: 0.182.. Accuracy: 0.944\n",
            "Epoch 6/35.. Training Loss: 0.410.. Validation Loss: 0.182.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.354.. Validation Loss: 0.180.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.397.. Validation Loss: 0.179.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.407.. Validation Loss: 0.178.. Accuracy: 0.945\n",
            "Epoch 6/35.. Training Loss: 0.393.. Validation Loss: 0.177.. Accuracy: 0.945\n",
            "Epoch 7/35.. Training Loss: 0.440.. Validation Loss: 0.176.. Accuracy: 0.946\n",
            "Epoch 7/35.. Training Loss: 0.366.. Validation Loss: 0.175.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.352.. Validation Loss: 0.175.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.440.. Validation Loss: 0.175.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.505.. Validation Loss: 0.176.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.439.. Validation Loss: 0.176.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.509.. Validation Loss: 0.177.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.428.. Validation Loss: 0.179.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.379.. Validation Loss: 0.179.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.451.. Validation Loss: 0.178.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.400.. Validation Loss: 0.178.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.410.. Validation Loss: 0.178.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.402.. Validation Loss: 0.176.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.486.. Validation Loss: 0.175.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.403.. Validation Loss: 0.176.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.386.. Validation Loss: 0.175.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.497.. Validation Loss: 0.175.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.437.. Validation Loss: 0.173.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.361.. Validation Loss: 0.174.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.404.. Validation Loss: 0.174.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.407.. Validation Loss: 0.174.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.392.. Validation Loss: 0.173.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.392.. Validation Loss: 0.172.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.465.. Validation Loss: 0.172.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.399.. Validation Loss: 0.171.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.416.. Validation Loss: 0.172.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.406.. Validation Loss: 0.172.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.440.. Validation Loss: 0.173.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.419.. Validation Loss: 0.174.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.368.. Validation Loss: 0.173.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.462.. Validation Loss: 0.173.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.390.. Validation Loss: 0.173.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.390.. Validation Loss: 0.172.. Accuracy: 0.947\n",
            "Epoch 7/35.. Training Loss: 0.386.. Validation Loss: 0.171.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.437.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.369.. Validation Loss: 0.170.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.350.. Validation Loss: 0.169.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.452.. Validation Loss: 0.169.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.428.. Validation Loss: 0.170.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.396.. Validation Loss: 0.171.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.436.. Validation Loss: 0.171.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.402.. Validation Loss: 0.170.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.479.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.449.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.399.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.420.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.401.. Validation Loss: 0.169.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.388.. Validation Loss: 0.169.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.394.. Validation Loss: 0.168.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.414.. Validation Loss: 0.167.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.412.. Validation Loss: 0.166.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.419.. Validation Loss: 0.166.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.425.. Validation Loss: 0.165.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.388.. Validation Loss: 0.165.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.443.. Validation Loss: 0.165.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.441.. Validation Loss: 0.166.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.509.. Validation Loss: 0.168.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.402.. Validation Loss: 0.169.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.425.. Validation Loss: 0.170.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.346.. Validation Loss: 0.170.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.364.. Validation Loss: 0.170.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.378.. Validation Loss: 0.169.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.346.. Validation Loss: 0.167.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.401.. Validation Loss: 0.166.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.401.. Validation Loss: 0.165.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.428.. Validation Loss: 0.165.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.378.. Validation Loss: 0.164.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.333.. Validation Loss: 0.163.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.409.. Validation Loss: 0.162.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.379.. Validation Loss: 0.163.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.479.. Validation Loss: 0.163.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.333.. Validation Loss: 0.163.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.392.. Validation Loss: 0.162.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.446.. Validation Loss: 0.162.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.421.. Validation Loss: 0.163.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.365.. Validation Loss: 0.162.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.389.. Validation Loss: 0.163.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.358.. Validation Loss: 0.163.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.367.. Validation Loss: 0.163.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.392.. Validation Loss: 0.164.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.399.. Validation Loss: 0.163.. Accuracy: 0.948\n",
            "Epoch 7/35.. Training Loss: 0.389.. Validation Loss: 0.162.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.392.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.356.. Validation Loss: 0.160.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.371.. Validation Loss: 0.159.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.349.. Validation Loss: 0.158.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.417.. Validation Loss: 0.157.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.366.. Validation Loss: 0.158.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.438.. Validation Loss: 0.159.. Accuracy: 0.951\n",
            "Epoch 7/35.. Training Loss: 0.311.. Validation Loss: 0.159.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.398.. Validation Loss: 0.160.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.318.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 7/35.. Training Loss: 0.400.. Validation Loss: 0.161.. Accuracy: 0.949\n",
            "Epoch 7/35.. Training Loss: 0.376.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.403.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.375.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.343.. Validation Loss: 0.161.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.402.. Validation Loss: 0.161.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.366.. Validation Loss: 0.160.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.388.. Validation Loss: 0.160.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.385.. Validation Loss: 0.159.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.345.. Validation Loss: 0.159.. Accuracy: 0.950\n",
            "Epoch 8/35.. Training Loss: 0.368.. Validation Loss: 0.158.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.387.. Validation Loss: 0.157.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.427.. Validation Loss: 0.158.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.376.. Validation Loss: 0.158.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.422.. Validation Loss: 0.159.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.427.. Validation Loss: 0.157.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.353.. Validation Loss: 0.157.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.375.. Validation Loss: 0.156.. Accuracy: 0.951\n",
            "Epoch 8/35.. Training Loss: 0.443.. Validation Loss: 0.156.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.383.. Validation Loss: 0.155.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.361.. Validation Loss: 0.156.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.439.. Validation Loss: 0.155.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.413.. Validation Loss: 0.157.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.429.. Validation Loss: 0.157.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.389.. Validation Loss: 0.157.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.361.. Validation Loss: 0.157.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.373.. Validation Loss: 0.157.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.415.. Validation Loss: 0.156.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.362.. Validation Loss: 0.156.. Accuracy: 0.952\n",
            "Epoch 8/35.. Training Loss: 0.339.. Validation Loss: 0.154.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.291.. Validation Loss: 0.153.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.394.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.393.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.393.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.382.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.438.. Validation Loss: 0.152.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.341.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.349.. Validation Loss: 0.153.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.435.. Validation Loss: 0.154.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.353.. Validation Loss: 0.153.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.457.. Validation Loss: 0.153.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.380.. Validation Loss: 0.153.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.374.. Validation Loss: 0.153.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.409.. Validation Loss: 0.152.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.350.. Validation Loss: 0.151.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.303.. Validation Loss: 0.151.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.402.. Validation Loss: 0.149.. Accuracy: 0.953\n",
            "Epoch 8/35.. Training Loss: 0.314.. Validation Loss: 0.149.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.351.. Validation Loss: 0.149.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.455.. Validation Loss: 0.149.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.346.. Validation Loss: 0.149.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.391.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.401.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.386.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.313.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.390.. Validation Loss: 0.148.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.418.. Validation Loss: 0.147.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.453.. Validation Loss: 0.147.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.352.. Validation Loss: 0.148.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.319.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.401.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.367.. Validation Loss: 0.148.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.344.. Validation Loss: 0.149.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.378.. Validation Loss: 0.149.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.363.. Validation Loss: 0.148.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.342.. Validation Loss: 0.146.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.378.. Validation Loss: 0.145.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.335.. Validation Loss: 0.145.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.456.. Validation Loss: 0.145.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.363.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.339.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.336.. Validation Loss: 0.147.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.325.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.307.. Validation Loss: 0.147.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.374.. Validation Loss: 0.147.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.374.. Validation Loss: 0.146.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.336.. Validation Loss: 0.146.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.335.. Validation Loss: 0.145.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.350.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.335.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.330.. Validation Loss: 0.146.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.411.. Validation Loss: 0.146.. Accuracy: 0.954\n",
            "Epoch 8/35.. Training Loss: 0.341.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.410.. Validation Loss: 0.145.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.378.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.401.. Validation Loss: 0.146.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.406.. Validation Loss: 0.147.. Accuracy: 0.955\n",
            "Epoch 8/35.. Training Loss: 0.415.. Validation Loss: 0.146.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.326.. Validation Loss: 0.146.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.343.. Validation Loss: 0.145.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.305.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.399.. Validation Loss: 0.143.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.350.. Validation Loss: 0.143.. Accuracy: 0.956\n",
            "Epoch 8/35.. Training Loss: 0.403.. Validation Loss: 0.143.. Accuracy: 0.957\n",
            "Epoch 8/35.. Training Loss: 0.390.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.408.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.377.. Validation Loss: 0.144.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.383.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.310.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.323.. Validation Loss: 0.144.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.292.. Validation Loss: 0.143.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.405.. Validation Loss: 0.142.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.399.. Validation Loss: 0.142.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.336.. Validation Loss: 0.141.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.355.. Validation Loss: 0.140.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.412.. Validation Loss: 0.141.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.337.. Validation Loss: 0.140.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.339.. Validation Loss: 0.139.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.434.. Validation Loss: 0.139.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.377.. Validation Loss: 0.140.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.352.. Validation Loss: 0.140.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.341.. Validation Loss: 0.140.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.287.. Validation Loss: 0.141.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.379.. Validation Loss: 0.141.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.368.. Validation Loss: 0.140.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.356.. Validation Loss: 0.142.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.307.. Validation Loss: 0.142.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.341.. Validation Loss: 0.142.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.369.. Validation Loss: 0.142.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.382.. Validation Loss: 0.141.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.340.. Validation Loss: 0.140.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.363.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.386.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.305.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.342.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.356.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.321.. Validation Loss: 0.139.. Accuracy: 0.956\n",
            "Epoch 9/35.. Training Loss: 0.342.. Validation Loss: 0.139.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.325.. Validation Loss: 0.138.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.344.. Validation Loss: 0.138.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.286.. Validation Loss: 0.137.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.331.. Validation Loss: 0.138.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.304.. Validation Loss: 0.138.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.390.. Validation Loss: 0.138.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.323.. Validation Loss: 0.137.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.375.. Validation Loss: 0.138.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.353.. Validation Loss: 0.137.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.373.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.343.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.340.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.314.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.352.. Validation Loss: 0.134.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.447.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.318.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.300.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.362.. Validation Loss: 0.137.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.299.. Validation Loss: 0.137.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.356.. Validation Loss: 0.137.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.325.. Validation Loss: 0.137.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.352.. Validation Loss: 0.137.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.354.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.389.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.351.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.333.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.309.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.277.. Validation Loss: 0.136.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.341.. Validation Loss: 0.136.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.352.. Validation Loss: 0.135.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.348.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.316.. Validation Loss: 0.134.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.318.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.375.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.362.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.363.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.343.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.338.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.274.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.305.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.350.. Validation Loss: 0.134.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.379.. Validation Loss: 0.135.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.274.. Validation Loss: 0.134.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.367.. Validation Loss: 0.134.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.357.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.366.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.301.. Validation Loss: 0.132.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.313.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.304.. Validation Loss: 0.132.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.354.. Validation Loss: 0.132.. Accuracy: 0.957\n",
            "Epoch 9/35.. Training Loss: 0.341.. Validation Loss: 0.132.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.362.. Validation Loss: 0.133.. Accuracy: 0.958\n",
            "Epoch 9/35.. Training Loss: 0.342.. Validation Loss: 0.134.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.320.. Validation Loss: 0.134.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.344.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.379.. Validation Loss: 0.133.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.308.. Validation Loss: 0.132.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.308.. Validation Loss: 0.132.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.322.. Validation Loss: 0.131.. Accuracy: 0.960\n",
            "Epoch 9/35.. Training Loss: 0.295.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 9/35.. Training Loss: 0.343.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.300.. Validation Loss: 0.129.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.323.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.423.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.316.. Validation Loss: 0.131.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.301.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.293.. Validation Loss: 0.130.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.329.. Validation Loss: 0.130.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.341.. Validation Loss: 0.130.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.352.. Validation Loss: 0.129.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.270.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.314.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.294.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.323.. Validation Loss: 0.128.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.318.. Validation Loss: 0.128.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.293.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.231.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.367.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.293.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.329.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.320.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.310.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.366.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.414.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.385.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.334.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.299.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.346.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.407.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.301.. Validation Loss: 0.128.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.366.. Validation Loss: 0.130.. Accuracy: 0.958\n",
            "Epoch 10/35.. Training Loss: 0.346.. Validation Loss: 0.130.. Accuracy: 0.958\n",
            "Epoch 10/35.. Training Loss: 0.359.. Validation Loss: 0.130.. Accuracy: 0.958\n",
            "Epoch 10/35.. Training Loss: 0.284.. Validation Loss: 0.129.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.440.. Validation Loss: 0.128.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.266.. Validation Loss: 0.126.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.320.. Validation Loss: 0.126.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.348.. Validation Loss: 0.125.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.327.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.336.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.365.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.292.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.343.. Validation Loss: 0.125.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.333.. Validation Loss: 0.126.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.355.. Validation Loss: 0.126.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.336.. Validation Loss: 0.126.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.348.. Validation Loss: 0.126.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.312.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.312.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.265.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.323.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.263.. Validation Loss: 0.128.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.380.. Validation Loss: 0.127.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.313.. Validation Loss: 0.126.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.316.. Validation Loss: 0.125.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.359.. Validation Loss: 0.124.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.311.. Validation Loss: 0.124.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.299.. Validation Loss: 0.124.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.337.. Validation Loss: 0.123.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.336.. Validation Loss: 0.123.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.357.. Validation Loss: 0.124.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.329.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.293.. Validation Loss: 0.124.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.316.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.309.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.304.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.378.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.331.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.311.. Validation Loss: 0.123.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.333.. Validation Loss: 0.123.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.320.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.312.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.320.. Validation Loss: 0.125.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.326.. Validation Loss: 0.125.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.329.. Validation Loss: 0.124.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.322.. Validation Loss: 0.124.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.306.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.321.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.372.. Validation Loss: 0.124.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.318.. Validation Loss: 0.123.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.357.. Validation Loss: 0.122.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.268.. Validation Loss: 0.123.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.314.. Validation Loss: 0.123.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.326.. Validation Loss: 0.123.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.317.. Validation Loss: 0.124.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.303.. Validation Loss: 0.124.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.310.. Validation Loss: 0.124.. Accuracy: 0.959\n",
            "Epoch 10/35.. Training Loss: 0.355.. Validation Loss: 0.123.. Accuracy: 0.960\n",
            "Epoch 10/35.. Training Loss: 0.346.. Validation Loss: 0.122.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.281.. Validation Loss: 0.122.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.343.. Validation Loss: 0.122.. Accuracy: 0.962\n",
            "Epoch 10/35.. Training Loss: 0.333.. Validation Loss: 0.122.. Accuracy: 0.962\n",
            "Epoch 10/35.. Training Loss: 0.297.. Validation Loss: 0.122.. Accuracy: 0.962\n",
            "Epoch 10/35.. Training Loss: 0.266.. Validation Loss: 0.122.. Accuracy: 0.961\n",
            "Epoch 10/35.. Training Loss: 0.332.. Validation Loss: 0.122.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.287.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.279.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.294.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.295.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.290.. Validation Loss: 0.120.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.277.. Validation Loss: 0.121.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.381.. Validation Loss: 0.121.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.276.. Validation Loss: 0.120.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.298.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.277.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.276.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.283.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.313.. Validation Loss: 0.120.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.346.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.271.. Validation Loss: 0.120.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.331.. Validation Loss: 0.121.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.295.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.309.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.330.. Validation Loss: 0.121.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.294.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.272.. Validation Loss: 0.119.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.275.. Validation Loss: 0.120.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.327.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.313.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.291.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.353.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.287.. Validation Loss: 0.118.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.264.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.298.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.296.. Validation Loss: 0.119.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.378.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.313.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.334.. Validation Loss: 0.120.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.302.. Validation Loss: 0.119.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.325.. Validation Loss: 0.118.. Accuracy: 0.961\n",
            "Epoch 11/35.. Training Loss: 0.324.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.339.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.303.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.272.. Validation Loss: 0.119.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.315.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.334.. Validation Loss: 0.117.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.281.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.283.. Validation Loss: 0.117.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.377.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.279.. Validation Loss: 0.118.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.285.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.335.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.337.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.307.. Validation Loss: 0.118.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.331.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.302.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.307.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.289.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.291.. Validation Loss: 0.115.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.282.. Validation Loss: 0.115.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.357.. Validation Loss: 0.115.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.354.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.350.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.292.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.281.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.311.. Validation Loss: 0.115.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.339.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.348.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.337.. Validation Loss: 0.114.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.270.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.329.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.299.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.283.. Validation Loss: 0.114.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.315.. Validation Loss: 0.115.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.343.. Validation Loss: 0.115.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.335.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.263.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.290.. Validation Loss: 0.117.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.263.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.350.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.262.. Validation Loss: 0.117.. Accuracy: 0.962\n",
            "Epoch 11/35.. Training Loss: 0.331.. Validation Loss: 0.116.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.282.. Validation Loss: 0.114.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.264.. Validation Loss: 0.113.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.299.. Validation Loss: 0.112.. Accuracy: 0.965\n",
            "Epoch 11/35.. Training Loss: 0.285.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.285.. Validation Loss: 0.113.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.252.. Validation Loss: 0.113.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.315.. Validation Loss: 0.113.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.345.. Validation Loss: 0.113.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.240.. Validation Loss: 0.113.. Accuracy: 0.963\n",
            "Epoch 11/35.. Training Loss: 0.260.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.361.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.354.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.343.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.314.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.316.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 11/35.. Training Loss: 0.331.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.304.. Validation Loss: 0.112.. Accuracy: 0.963\n",
            "Epoch 12/35.. Training Loss: 0.322.. Validation Loss: 0.112.. Accuracy: 0.963\n",
            "Epoch 12/35.. Training Loss: 0.330.. Validation Loss: 0.112.. Accuracy: 0.963\n",
            "Epoch 12/35.. Training Loss: 0.313.. Validation Loss: 0.112.. Accuracy: 0.963\n",
            "Epoch 12/35.. Training Loss: 0.264.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.281.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.308.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.406.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.258.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.320.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.288.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.298.. Validation Loss: 0.112.. Accuracy: 0.963\n",
            "Epoch 12/35.. Training Loss: 0.325.. Validation Loss: 0.112.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.337.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.260.. Validation Loss: 0.111.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.288.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.320.. Validation Loss: 0.110.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.311.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.295.. Validation Loss: 0.110.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.287.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.262.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.291.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.303.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.307.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.278.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.328.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.308.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.250.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.323.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.315.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.312.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.347.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.346.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.283.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.375.. Validation Loss: 0.111.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.303.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.286.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.302.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.286.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.294.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.328.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.353.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.297.. Validation Loss: 0.111.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.306.. Validation Loss: 0.111.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.360.. Validation Loss: 0.110.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.348.. Validation Loss: 0.110.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.216.. Validation Loss: 0.109.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.288.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.260.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.270.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.254.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.265.. Validation Loss: 0.107.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.299.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.284.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.313.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.328.. Validation Loss: 0.107.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.257.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.301.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.306.. Validation Loss: 0.109.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.295.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.276.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.324.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.272.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.342.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.315.. Validation Loss: 0.108.. Accuracy: 0.964\n",
            "Epoch 12/35.. Training Loss: 0.252.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.351.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.260.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.326.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.259.. Validation Loss: 0.108.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.263.. Validation Loss: 0.109.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.256.. Validation Loss: 0.109.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.323.. Validation Loss: 0.109.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.273.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.290.. Validation Loss: 0.109.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.343.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.256.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.296.. Validation Loss: 0.108.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.250.. Validation Loss: 0.107.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.273.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 12/35.. Training Loss: 0.272.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.290.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.258.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.316.. Validation Loss: 0.105.. Accuracy: 0.967\n",
            "Epoch 12/35.. Training Loss: 0.309.. Validation Loss: 0.106.. Accuracy: 0.967\n",
            "Epoch 12/35.. Training Loss: 0.220.. Validation Loss: 0.107.. Accuracy: 0.967\n",
            "Epoch 12/35.. Training Loss: 0.317.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.289.. Validation Loss: 0.106.. Accuracy: 0.967\n",
            "Epoch 12/35.. Training Loss: 0.243.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.287.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.298.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.315.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.302.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 12/35.. Training Loss: 0.267.. Validation Loss: 0.106.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.296.. Validation Loss: 0.106.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.274.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.256.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.287.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.301.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.270.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.233.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.299.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.289.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.282.. Validation Loss: 0.107.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.221.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.307.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.242.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.282.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.269.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.284.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.341.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.282.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.302.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.277.. Validation Loss: 0.107.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.336.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.305.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.326.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.291.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.294.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.259.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.324.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.264.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.256.. Validation Loss: 0.106.. Accuracy: 0.964\n",
            "Epoch 13/35.. Training Loss: 0.243.. Validation Loss: 0.106.. Accuracy: 0.965\n",
            "Epoch 13/35.. Training Loss: 0.259.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.295.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.238.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.311.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.314.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.313.. Validation Loss: 0.104.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.272.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.301.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.307.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.306.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.286.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.275.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.355.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.286.. Validation Loss: 0.106.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.292.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.300.. Validation Loss: 0.105.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.264.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.347.. Validation Loss: 0.104.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.304.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.268.. Validation Loss: 0.104.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.311.. Validation Loss: 0.103.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.293.. Validation Loss: 0.103.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.290.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.297.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.239.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.240.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.267.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.239.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.247.. Validation Loss: 0.103.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.292.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.287.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.303.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.249.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.220.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.333.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.276.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.299.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.310.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.268.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.266.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.290.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.241.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.368.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.283.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.246.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.271.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.315.. Validation Loss: 0.103.. Accuracy: 0.966\n",
            "Epoch 13/35.. Training Loss: 0.342.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.322.. Validation Loss: 0.103.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.270.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.270.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.259.. Validation Loss: 0.102.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.280.. Validation Loss: 0.101.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.256.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.249.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.258.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.305.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.219.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 13/35.. Training Loss: 0.286.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.304.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.274.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.286.. Validation Loss: 0.100.. Accuracy: 0.968\n",
            "Epoch 13/35.. Training Loss: 0.330.. Validation Loss: 0.101.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.275.. Validation Loss: 0.101.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.262.. Validation Loss: 0.101.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.219.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.231.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.264.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.294.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.240.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.285.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.232.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.290.. Validation Loss: 0.100.. Accuracy: 0.966\n",
            "Epoch 14/35.. Training Loss: 0.253.. Validation Loss: 0.099.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.244.. Validation Loss: 0.099.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.281.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.319.. Validation Loss: 0.099.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.259.. Validation Loss: 0.099.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.345.. Validation Loss: 0.099.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.292.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.270.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.279.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.307.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.243.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.241.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.307.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.253.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.347.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.238.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.325.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.233.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.237.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.255.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.298.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.294.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.235.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.242.. Validation Loss: 0.102.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.226.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.312.. Validation Loss: 0.101.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.300.. Validation Loss: 0.100.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.258.. Validation Loss: 0.099.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.228.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.235.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.294.. Validation Loss: 0.097.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.300.. Validation Loss: 0.097.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.264.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.257.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.334.. Validation Loss: 0.096.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.244.. Validation Loss: 0.096.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.279.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.260.. Validation Loss: 0.097.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.263.. Validation Loss: 0.097.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.238.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.271.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.310.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.250.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.279.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.279.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.282.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.285.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.249.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.232.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.315.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.233.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.226.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.316.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.326.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.269.. Validation Loss: 0.099.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.232.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.293.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.300.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.310.. Validation Loss: 0.098.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.257.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.233.. Validation Loss: 0.098.. Accuracy: 0.967\n",
            "Epoch 14/35.. Training Loss: 0.322.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.298.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.247.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.254.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.198.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.262.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.222.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.252.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.303.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.296.. Validation Loss: 0.098.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.337.. Validation Loss: 0.098.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.315.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.271.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.287.. Validation Loss: 0.097.. Accuracy: 0.968\n",
            "Epoch 14/35.. Training Loss: 0.287.. Validation Loss: 0.097.. Accuracy: 0.969\n",
            "Epoch 14/35.. Training Loss: 0.305.. Validation Loss: 0.097.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.277.. Validation Loss: 0.097.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.285.. Validation Loss: 0.097.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.243.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.239.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.280.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.252.. Validation Loss: 0.097.. Accuracy: 0.970\n",
            "Epoch 14/35.. Training Loss: 0.217.. Validation Loss: 0.097.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.227.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.247.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.286.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.285.. Validation Loss: 0.095.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.292.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.286.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.267.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.249.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.283.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.250.. Validation Loss: 0.095.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.261.. Validation Loss: 0.096.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.292.. Validation Loss: 0.095.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.275.. Validation Loss: 0.095.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.217.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.269.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.296.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.249.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.230.. Validation Loss: 0.096.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.280.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.265.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.240.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.274.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.267.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.259.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.271.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.277.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.228.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.262.. Validation Loss: 0.095.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.245.. Validation Loss: 0.095.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.215.. Validation Loss: 0.095.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.299.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.255.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.291.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.295.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.214.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.257.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.222.. Validation Loss: 0.095.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.277.. Validation Loss: 0.095.. Accuracy: 0.968\n",
            "Epoch 15/35.. Training Loss: 0.270.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.260.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.279.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.205.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.267.. Validation Loss: 0.096.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.293.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.222.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.279.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.209.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.263.. Validation Loss: 0.095.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.255.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.272.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.295.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.310.. Validation Loss: 0.095.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.253.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.273.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.256.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.244.. Validation Loss: 0.094.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.283.. Validation Loss: 0.093.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.277.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.294.. Validation Loss: 0.092.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.296.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.261.. Validation Loss: 0.092.. Accuracy: 0.969\n",
            "Epoch 15/35.. Training Loss: 0.272.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.213.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.278.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.273.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.202.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.249.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.257.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.339.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.215.. Validation Loss: 0.092.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.218.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.249.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.336.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.233.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.235.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.309.. Validation Loss: 0.093.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.280.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.256.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.238.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.291.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.280.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.218.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.239.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.202.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.264.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.254.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.287.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.233.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.270.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.255.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.254.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.213.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 15/35.. Training Loss: 0.222.. Validation Loss: 0.091.. Accuracy: 0.971\n",
            "Epoch 15/35.. Training Loss: 0.287.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.239.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.230.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.236.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.282.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.279.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.222.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.300.. Validation Loss: 0.092.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.299.. Validation Loss: 0.092.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.212.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.270.. Validation Loss: 0.092.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.239.. Validation Loss: 0.093.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.294.. Validation Loss: 0.093.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.233.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.233.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.271.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.325.. Validation Loss: 0.094.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.224.. Validation Loss: 0.093.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.282.. Validation Loss: 0.092.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.224.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.253.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.243.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.251.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.265.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.212.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.251.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.304.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.287.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.221.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.248.. Validation Loss: 0.091.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.236.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.217.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.252.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.251.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.231.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.242.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.291.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.260.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.273.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.222.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.259.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.204.. Validation Loss: 0.090.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.213.. Validation Loss: 0.090.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.252.. Validation Loss: 0.090.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.237.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.282.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.270.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.303.. Validation Loss: 0.090.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.255.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.231.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.216.. Validation Loss: 0.090.. Accuracy: 0.969\n",
            "Epoch 16/35.. Training Loss: 0.206.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.266.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.217.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.227.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.264.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.251.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.248.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.270.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.218.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.281.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.251.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.267.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.269.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.231.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.282.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.279.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.248.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.293.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.268.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.229.. Validation Loss: 0.090.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.261.. Validation Loss: 0.089.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.233.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.249.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.219.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.235.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.213.. Validation Loss: 0.088.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.266.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.273.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.238.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.287.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.260.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.243.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.255.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.227.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.256.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.275.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.209.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.241.. Validation Loss: 0.088.. Accuracy: 0.970\n",
            "Epoch 16/35.. Training Loss: 0.272.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.232.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.288.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.243.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 16/35.. Training Loss: 0.282.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.276.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.307.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.250.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.233.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.246.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.281.. Validation Loss: 0.089.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.225.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.210.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.262.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.233.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.210.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.334.. Validation Loss: 0.088.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.237.. Validation Loss: 0.088.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.247.. Validation Loss: 0.088.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.270.. Validation Loss: 0.088.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.257.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.237.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.182.. Validation Loss: 0.087.. Accuracy: 0.970\n",
            "Epoch 17/35.. Training Loss: 0.288.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.197.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.256.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.245.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.229.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.221.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.295.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.270.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.228.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.252.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.243.. Validation Loss: 0.087.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.250.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.215.. Validation Loss: 0.086.. Accuracy: 0.970\n",
            "Epoch 17/35.. Training Loss: 0.259.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.245.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.251.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.219.. Validation Loss: 0.085.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.258.. Validation Loss: 0.085.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.268.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.186.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.252.. Validation Loss: 0.086.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.322.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.272.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.233.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.230.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.259.. Validation Loss: 0.085.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.184.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.240.. Validation Loss: 0.085.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.256.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.261.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.290.. Validation Loss: 0.086.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.214.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.224.. Validation Loss: 0.086.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.263.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.209.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.278.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.222.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.189.. Validation Loss: 0.086.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.270.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.226.. Validation Loss: 0.086.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.247.. Validation Loss: 0.086.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.240.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.227.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.235.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.252.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.245.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.254.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.245.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.250.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.258.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.216.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.254.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.209.. Validation Loss: 0.084.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.222.. Validation Loss: 0.085.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.275.. Validation Loss: 0.085.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.247.. Validation Loss: 0.085.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.241.. Validation Loss: 0.084.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.253.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.263.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.227.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.227.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.253.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.288.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.205.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.241.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.243.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.246.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.220.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.236.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 17/35.. Training Loss: 0.213.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.236.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.207.. Validation Loss: 0.083.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.271.. Validation Loss: 0.082.. Accuracy: 0.971\n",
            "Epoch 17/35.. Training Loss: 0.255.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.258.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 17/35.. Training Loss: 0.217.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.227.. Validation Loss: 0.081.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.229.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.301.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.278.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.229.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.220.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.302.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.274.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.253.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.258.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.249.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.269.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.214.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.275.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.231.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.299.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.233.. Validation Loss: 0.084.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.233.. Validation Loss: 0.084.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.231.. Validation Loss: 0.084.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.327.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.187.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.256.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.236.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.199.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.212.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.261.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.279.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.224.. Validation Loss: 0.084.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.269.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.248.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.267.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.256.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.223.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.214.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.288.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.252.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.249.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.254.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.213.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.236.. Validation Loss: 0.081.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.187.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.260.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.217.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.186.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.216.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.186.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.260.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.214.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.249.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.250.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.205.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.219.. Validation Loss: 0.083.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.259.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.189.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.224.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.247.. Validation Loss: 0.081.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.250.. Validation Loss: 0.081.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.222.. Validation Loss: 0.081.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.195.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.234.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.275.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.221.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.228.. Validation Loss: 0.082.. Accuracy: 0.972\n",
            "Epoch 18/35.. Training Loss: 0.208.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.277.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.191.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.237.. Validation Loss: 0.083.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.246.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.243.. Validation Loss: 0.082.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.204.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.221.. Validation Loss: 0.081.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.264.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.241.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.239.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.225.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.207.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.239.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.259.. Validation Loss: 0.081.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.276.. Validation Loss: 0.081.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.219.. Validation Loss: 0.081.. Accuracy: 0.974\n",
            "Epoch 18/35.. Training Loss: 0.179.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.217.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.198.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.234.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.224.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.290.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.252.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 18/35.. Training Loss: 0.234.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.246.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.217.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.217.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.243.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.254.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.200.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.264.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.207.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.187.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.216.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.253.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.198.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.237.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.242.. Validation Loss: 0.081.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.197.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.250.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.227.. Validation Loss: 0.080.. Accuracy: 0.972\n",
            "Epoch 19/35.. Training Loss: 0.249.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.230.. Validation Loss: 0.080.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.236.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.235.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.208.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.265.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.266.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.226.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.212.. Validation Loss: 0.079.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.239.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.221.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.235.. Validation Loss: 0.079.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.165.. Validation Loss: 0.079.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.241.. Validation Loss: 0.079.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.170.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.214.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.256.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.243.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.279.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.220.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.268.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.236.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.259.. Validation Loss: 0.079.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.247.. Validation Loss: 0.079.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.247.. Validation Loss: 0.079.. Accuracy: 0.973\n",
            "Epoch 19/35.. Training Loss: 0.212.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.242.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.215.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.246.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.255.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.268.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.249.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.199.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.187.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.254.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.223.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.199.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.233.. Validation Loss: 0.081.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.261.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.203.. Validation Loss: 0.080.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.184.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.246.. Validation Loss: 0.079.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.297.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.293.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.206.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.240.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.202.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.261.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.216.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.270.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.233.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.208.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.266.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.243.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.266.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 19/35.. Training Loss: 0.226.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.209.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.268.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.260.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.252.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.238.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.262.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.255.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.203.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.234.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.210.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.303.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.238.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.280.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.186.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.217.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.210.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.196.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.269.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.205.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.234.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 19/35.. Training Loss: 0.193.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.240.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.276.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.234.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.170.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.297.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.283.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.204.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.236.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.228.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.256.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.218.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.250.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.226.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.238.. Validation Loss: 0.079.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.175.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.298.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.195.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.218.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.241.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.185.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.206.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.216.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.224.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.199.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.216.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.216.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.193.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.240.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.243.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.176.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.286.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.246.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.191.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.221.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.211.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.207.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.208.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.276.. Validation Loss: 0.077.. Accuracy: 0.973\n",
            "Epoch 20/35.. Training Loss: 0.209.. Validation Loss: 0.077.. Accuracy: 0.973\n",
            "Epoch 20/35.. Training Loss: 0.236.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.192.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.278.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.220.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 20/35.. Training Loss: 0.242.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.251.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 20/35.. Training Loss: 0.188.. Validation Loss: 0.076.. Accuracy: 0.975\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-31dac0b3380b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3513d922a570>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ps I stopped the training when I noticed that the accuracy stabalized ^"
      ],
      "metadata": {
        "id": "KGxgkQJGXyMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYDgxBNLl2Yz"
      },
      "source": [
        "Plot the training loss (and validation loss/accuracy, if recorded)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss history\n",
        "plt.plot(train_loss_history, label=\"Training Loss\")\n",
        "plt.plot(valid_loss_history, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tBn-wDq0myKC",
        "outputId": "2548f11a-dbf4-4533-8220-77d7f2425a16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA42ElEQVR4nO3deXxU1cHG8WeSkI1srEnAICA7RkA2A61oTRuQIlhbeCkVVNDqG1DEBamyuAarKC4oLq9QWxXEAlpAMSCLQJQ1EGQRNRKUJMiWEJas5/1jmpGRLQmZnEny+34+8yFz58y9z5kE8nDnzr0OY4wRAACAJT62AwAAgNqNMgIAAKyijAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjAADAKj/bAcqipKRE+/fvV2hoqBwOh+04AACgDIwxOnbsmJo0aSIfn3Pv/6gWZWT//v2KiYmxHQMAAFTAvn37dMkll5zz8WpRRkJDQyU5JxMWFmY5DQAAKIvc3FzFxMS4fo+fS7UoI6VvzYSFhVFGAACoZi50iAUHsAIAAKsoIwAAwCrKCAAAsKpaHDMCAKg4Y4yKiopUXFxsOwpqGF9fX/n5+V30aTcoIwBQgxUUFCgzM1MnTpywHQU1VHBwsKKjo+Xv71/hdVBGAKCGKikpUXp6unx9fdWkSRP5+/tz4khUGmOMCgoK9NNPPyk9PV2tW7c+74nNzocyAgA1VEFBgUpKShQTE6Pg4GDbcVADBQUFqU6dOtq7d68KCgoUGBhYofVwACsA1HAV/d8qUBaV8fPFTygAALCKMgIAqBWaN2+u6dOnl3n8ypUr5XA4dPToUY9lghNlBADgVRwOx3lvU6ZMqdB6N2zYoDvuuKPM43v16qXMzEyFh4dXaHtlRenhAFYAgJfJzMx0fT137lxNmjRJu3fvdi0LCQlxfW2MUXFxsfz8LvzrrFGjRuXK4e/vr6ioqHI9BxVTu/eM5P0kPdNK2vCm7SQAgP+Kiopy3cLDw+VwOFz3d+3apdDQUH388cfq2rWrAgICtGbNGn377bcaOHCgIiMjFRISou7du2vZsmVu6/3l2zQOh0NvvvmmbrzxRgUHB6t169b66KOPXI//co/F7NmzFRERoaVLl6p9+/YKCQlR37593cpTUVGR7r77bkVERKhBgwYaP368RowYoUGDBlX49Thy5IiGDx+uevXqKTg4WP369dOePXtcj+/du1cDBgxQvXr1VLduXXXs2FFLlixxPXfYsGFq1KiRgoKC1Lp1a82aNavCWTyldpeRZ1tJx3+SFt8nTQmXigpsJwIAjzLG6ERBkZWbMabS5vHQQw9p6tSp2rlzp6644grl5eXp+uuv1/Lly7Vlyxb17dtXAwYMUEZGxnnX8+ijj2rw4MHatm2brr/+eg0bNkyHDx8+5/gTJ07o2Wef1T//+U+tXr1aGRkZuv/++12PP/3003rnnXc0a9YsrV27Vrm5uVq4cOFFzfWWW27Rxo0b9dFHHyklJUXGGF1//fUqLCyUJCUmJio/P1+rV69WWlqann76adfeo4kTJ2rHjh36+OOPtXPnTr366qtq2LDhReXxBN6mOd0TjaSEJCnuf20nAQCPOFlYrA6TllrZ9o7HEhTsXzm/dh577DH99re/dd2vX7++OnXq5Lr/+OOPa8GCBfroo480evToc67nlltu0dChQyVJTz31lF588UWtX79effv2Pev4wsJCzZw5U5dddpkkafTo0Xrsscdcj7/00kuaMGGCbrzxRknSyy+/7NpLURF79uzRRx99pLVr16pXr16SpHfeeUcxMTFauHCh/vSnPykjI0M33XSTYmNjJUktW7Z0PT8jI0NdunRRt27dJDn3Dnmj2r1n5GyWTnDuJSkusp0EAHAOpb9cS+Xl5en+++9X+/btFRERoZCQEO3cufOCe0auuOIK19d169ZVWFiYDhw4cM7xwcHBriIiSdHR0a7xOTk5ys7OVo8ePVyP+/r6qmvXruWa2+l27twpPz8/9ezZ07WsQYMGatu2rXbu3ClJuvvuu/XEE0+od+/emjx5srZt2+Yae9ddd2nOnDnq3LmzHnzwQa1bt67CWTyJPSPn8ngD6fYVUtMrbScBgEoTVMdXOx5LsLbtylK3bl23+/fff7+Sk5P17LPPqlWrVgoKCtIf//hHFRSc/+33OnXquN13OBwqKSkp1/jKfPupIkaNGqWEhAQtXrxYn376qZKSkjRt2jSNGTNG/fr10969e7VkyRIlJyfruuuuU2Jiop599lmrmX+JPSPn88a1UtoHtlMAQKVxOBwK9vezcvPkdXHWrl2rW265RTfeeKNiY2MVFRWl77//3mPbO5vw8HBFRkZqw4YNrmXFxcXavHlzhdfZvn17FRUV6csvv3QtO3TokHbv3q0OHTq4lsXExOjOO+/U/Pnzdd999+mNN95wPdaoUSONGDFC//rXvzR9+nS9/vrrFc7jKewZuZB/j3T+GftHuzkAAOfUunVrzZ8/XwMGDJDD4dDEiRPPu4fDU8aMGaOkpCS1atVK7dq100svvaQjR46UqYilpaUpNDTUdd/hcKhTp04aOHCgbr/9dr322msKDQ3VQw89pKZNm2rgwIGSpLFjx6pfv35q06aNjhw5ohUrVqh9+/aSpEmTJqlr167q2LGj8vPztWjRItdj3oQyUhb/Hik1bCNFX3HhsQCAKvfcc8/ptttuU69evdSwYUONHz9eubm5VZ5j/PjxysrK0vDhw+Xr66s77rhDCQkJ8vW98FtUV199tdt9X19fFRUVadasWbrnnnv0+9//XgUFBbr66qu1ZMkS11tGxcXFSkxM1A8//KCwsDD17dtXzz//vCTnuVImTJig77//XkFBQfr1r3+tOXPmVP7EL5LD2H6zqwxyc3MVHh6unJwchYWFVd6Kp5TzrHoTD0m+9DcA1cOpU6eUnp6uFi1aVPhqqrg4JSUlat++vQYPHqzHH3/cdhyPON/PWVl/f3PMSHk83sB2AgCAF9u7d6/eeOMNff3110pLS9Ndd92l9PR0/fnPf7YdzatRRspr5yLbCQAAXsrHx0ezZ89W9+7d1bt3b6WlpWnZsmVeeZyGN+E9h/KaO0yakmM7BQDAC8XExGjt2rW2Y1Q77BmpiAV32k4AAECNQRmpiK3v2U4AAECNQRmpqM+esJ0AAIAagTJSUaufsZ0AAIAagTJyMTK32k4AAEC1Rxm5GK9dfeExAADgvCgjF8v7T2ALALXSNddco7Fjx7ruN2/eXNOnTz/vcxwOhxYuXHjR266s9dQWlJGLte5F2wkAoEYZMGCA+vbte9bHPv/8czkcDm3btq3c692wYYPuuOOOi43nZsqUKercufMZyzMzM9WvX79K3dYvzZ49WxERER7dRlWhjFys5Em2EwBAjTJy5EglJyfrhx9+OOOxWbNmqVu3brriivJfuLRRo0YKDg6ujIgXFBUVpYCAgCrZVk1AGQEAeJXf//73atSokWbPnu22PC8vT/PmzdPIkSN16NAhDR06VE2bNlVwcLBiY2P13nvnPwfUL9+m2bNnj66++moFBgaqQ4cOSk5OPuM548ePV5s2bRQcHKyWLVtq4sSJKiwslOTcM/Hoo49q69atcjgccjgcrsy/fJsmLS1Nv/nNbxQUFKQGDRrojjvuUF5enuvxW265RYMGDdKzzz6r6OhoNWjQQImJia5tVURGRoYGDhyokJAQhYWFafDgwcrOznY9vnXrVl177bUKDQ1VWFiYunbtqo0bN0pyXmNnwIABqlevnurWrauOHTtqyZIlFc5yIZwOvjJ8+5l02W9spwCACzNGKjxhZ9t1giWH44LD/Pz8NHz4cM2ePVsPP/ywHP99zrx581RcXKyhQ4cqLy9PXbt21fjx4xUWFqbFixfr5ptv1mWXXaYePXpccBslJSX6wx/+oMjISH355ZfKyclxO76kVGhoqGbPnq0mTZooLS1Nt99+u0JDQ/Xggw9qyJAh2r59uz755BMtW7ZMkhQefubV4I8fP66EhATFxcVpw4YNOnDggEaNGqXRo0e7Fa4VK1YoOjpaK1as0DfffKMhQ4aoc+fOuv322y84n7PNr7SIrFq1SkVFRUpMTNSQIUO0cuVKSdKwYcPUpUsXvfrqq/L19VVqaqrq1KkjSUpMTFRBQYFWr16tunXraseOHQoJCSl3jrKijFSGf97I9WoAVA+FJ6SnmtjZ9t/2S/51yzT0tttu0zPPPKNVq1bpmmuukeR8i+amm25SeHi4wsPDdf/997vGjxkzRkuXLtX7779fpjKybNky7dq1S0uXLlWTJs7X46mnnjrjOI9HHnnE9XXz5s11//33a86cOXrwwQcVFBSkkJAQ+fn5KSoq6pzbevfdd3Xq1Cm9/fbbqlvXOf+XX35ZAwYM0NNPP63IyEhJUr169fTyyy/L19dX7dq1U//+/bV8+fIKlZHly5crLS1N6enpiomJkSS9/fbb6tixozZs2KDu3bsrIyNDDzzwgNq1aydJat26tev5GRkZuummmxQbGytJatmyZbkzlAdv0wAAvE67du3Uq1cvvfXWW5Kkb775Rp9//rlGjhwpSSouLtbjjz+u2NhY1a9fXyEhIVq6dKkyMjLKtP6dO3cqJibGVUQkKS4u7oxxc+fOVe/evRUVFaWQkBA98sgjZd7G6dvq1KmTq4hIUu/evVVSUqLdu3e7lnXs2FG+vr6u+9HR0Tpw4EC5tnX6NmNiYlxFRJI6dOigiIgI7dy5U5I0btw4jRo1SvHx8Zo6daq+/fZb19i7775bTzzxhHr37q3JkydX6IDh8mDPSGUxpky7HwHAqjrBzj0UtrZdDiNHjtSYMWM0Y8YMzZo1S5dddpn69OkjSXrmmWf0wgsvaPr06YqNjVXdunU1duxYFRQUVFrclJQUDRs2TI8++qgSEhIUHh6uOXPmaNq0aZW2jdOVvkVSyuFwqKSkxCPbkpyfBPrzn/+sxYsX6+OPP9bkyZM1Z84c3XjjjRo1apQSEhK0ePFiffrpp0pKStK0adM0ZswYj2Rhz0hl+X6N7QQAcGEOh/OtEhu3cv6HbfDgwfLx8dG7776rt99+W7fddpvr+JG1a9dq4MCB+stf/qJOnTqpZcuW+vrrr8u87vbt22vfvn3KzMx0Lfviiy/cxqxbt06XXnqpHn74YXXr1k2tW7fW3r173cb4+/uruLj4gtvaunWrjh8/7lq2du1a+fj4qG3btmXOXB6l89u3b59r2Y4dO3T06FF16NDBtaxNmza699579emnn+oPf/iDZs2a5XosJiZGd955p+bPn6/77rtPb7zxhkeySpSRyvNhou0EAFCjhISEaMiQIZowYYIyMzN1yy23uB5r3bq1kpOTtW7dOu3cuVN//etf3T4pciHx8fFq06aNRowYoa1bt+rzzz/Xww8/7DamdevWysjI0Jw5c/Ttt9/qxRdf1IIFC9zGNG/eXOnp6UpNTdXBgweVn59/xraGDRumwMBAjRgxQtu3b9eKFSs0ZswY3Xzzza7jRSqquLhYqampbredO3cqPj5esbGxGjZsmDZv3qz169dr+PDh6tOnj7p166aTJ09q9OjRWrlypfbu3au1a9dqw4YNat++vSRp7NixWrp0qdLT07V582atWLHC9ZgnUEYqy9G9Fx4DACiXkSNH6siRI0pISHA7vuORRx7RlVdeqYSEBF1zzTWKiorSoEGDyrxeHx8fLViwQCdPnlSPHj00atQoPfnkk25jbrjhBt17770aPXq0OnfurHXr1mnixIluY2666Sb17dtX1157rRo1anTWjxcHBwdr6dKlOnz4sLp3764//vGPuu666/Tyyy+X78U4i7y8PHXp0sXtNmDAADkcDn344YeqV6+err76asXHx6tly5aaO3euJMnX11eHDh3S8OHD1aZNGw0ePFj9+vXTo48+KslZchITE9W+fXv17dtXbdq00SuvvHLRec/FYYz3n888NzdX4eHhysnJUVhYWOWteMqZH8G6uPXxiRoA3uPUqVNKT09XixYtFBgYaDsOaqjz/ZyV9fc3e0Yqk/f3OgAAvA5lpDL9sNF2AgAAqh3KSGVaNdV2AgAAqh3KSGX6ZpntBAAAVDuUEQAAYBVlBABquGrwoUlUY5Xx80UZqWwnDttOAACSfj69+IkTlq7Si1qh9Ofrl6ezLw+uTVPZsrdLLa62nQIA5Ovrq4iICNfF1oKDg12nUwculjFGJ06c0IEDBxQREeF2kb/yooxUtuWPS6OSbacAAElyXdq+old/BS4kIiLC9XNWUZSRyvbDetsJAMDF4XAoOjpajRs3VmFhoe04qGHq1KlzUXtESlFGAKAW8PX1rZRfGoAncAArAACwqlxlJCkpSd27d1doaKgaN26sQYMGaffu3Rd83rx589SuXTsFBgYqNjZWS5YsqXBgAABQs5SrjKxatUqJiYn64osvlJycrMLCQv3ud7/T8ePHz/mcdevWaejQoRo5cqS2bNmiQYMGadCgQdq+fftFh/dax7JsJwAAoNpwmIs4W8lPP/2kxo0ba9WqVbr66rN/nHXIkCE6fvy4Fi1a5Fp21VVXqXPnzpo5c2aZtlPWSxCX25TwylvX6f66Woru5Jl1AwBQTZT19/dFHTOSk5MjSapfv/45x6SkpCg+Pt5tWUJCglJSUs75nPz8fOXm5rrdqpXPp9lOAABAtVHhMlJSUqKxY8eqd+/euvzyy885LisrS5GRkW7LIiMjlZV17rcykpKSFB4e7rrFxMRUNKYdXy+1nQAAgGqjwmUkMTFR27dv15w5cyozjyRpwoQJysnJcd327dtX6dvwqKJTthMAAFBtVOg8I6NHj9aiRYu0evVqXXLJJecdGxUVpezsbLdl2dnZ5z1bW0BAgAICAioSDQAAVDPl2jNijNHo0aO1YMECffbZZ2rRosUFnxMXF6fly5e7LUtOTlZcXFz5kgIAgBqpXHtGEhMT9e677+rDDz9UaGio67iP8PBwBQUFSZKGDx+upk2bKikpSZJ0zz33qE+fPpo2bZr69++vOXPmaOPGjXr99dcreSoAAKA6KteekVdffVU5OTm65pprFB0d7brNnTvXNSYjI0OZmZmu+7169dK7776r119/XZ06ddIHH3yghQsXnveg1xrh+CHbCQAAqBYu6jwjVaXanWdEku7ZJtW71HPrBwDAy1XJeUZwHmnzbCcAAKBaoIx4Svpq2wkAAKgWKCOekr7KdgIAAKoFyggAALCKMgIAAKyijAAAAKsoIwAAwCrKCAAAsIoy4kl5B2wnAADA61FGPMmU2E4AAIDXo4x40qFvbScAAMDrUUY8KWWG7QQAAHg9yggAALCKMuJJuxfbTgAAgNejjAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjnlZcZDsBAABejTLiafm5thMAAODVKCMAAMAqyoinHfzadgIAALwaZcTTNvyf7QQAAHg1yggAALCKMuJpP260nQAAAK9GGfG0w9/ZTgAAgFejjAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjAADAKspIVSg4YTsBAABeizJSFUyx7QQAAHgtyggAALCKMlIVDqfbTgAAgNeijFSFjW/ZTgAAgNeijFQFh8N2AgAAvBZlpCrkH7OdAAAAr0UZqQpp82wnAADAa1FGAACAVZQRAABgFWUEAABYRRkBAABWUUYAAIBVlBEAAGAVZaSqGGM7AQAAXokyUlWK8m0nAADAK1FGqgqnhAcA4KwoI1XFlNhOAACAV6KMVJXt820nAADAK1FGqspPO20nAADAK1FGAACAVZSRqnJwj+0EAAB4JcpIVfn6E9sJAADwSpQRAABgFWUEAABYRRkBAABWUUYAAIBVlBEAAGAVZQQAAFhV7jKyevVqDRgwQE2aNJHD4dDChQvPO37lypVyOBxn3LKysiqaufoyxnYCAAC8TrnLyPHjx9WpUyfNmDGjXM/bvXu3MjMzXbfGjRuXd9MAAKAG8ivvE/r166d+/fqVe0ONGzdWREREuZ8HAABqtio7ZqRz586Kjo7Wb3/7W61du/a8Y/Pz85Wbm+t2qxFO5dhOAACA1/F4GYmOjtbMmTP173//W//+978VExOja665Rps3bz7nc5KSkhQeHu66xcTEeDpm1djwhu0EAAB4nXK/TVNebdu2Vdu2bV33e/XqpW+//VbPP/+8/vnPf571ORMmTNC4ceNc93Nzc2tGISkusp0AAACv4/EycjY9evTQmjVrzvl4QECAAgICqjARAACwxcp5RlJTUxUdHW1j03b9uNF2AgAAvE6594zk5eXpm2++cd1PT09Xamqq6tevr2bNmmnChAn68ccf9fbbb0uSpk+frhYtWqhjx446deqU3nzzTX322Wf69NNPK28W1cU3y2wnAADA65S7jGzcuFHXXnut637psR0jRozQ7NmzlZmZqYyMDNfjBQUFuu+++/Tjjz8qODhYV1xxhZYtW+a2DgAAUHs5jPH+04Lm5uYqPDxcOTk5CgsLq7wVTwmvvHWVeZt8vBcAUDuU9fc316YBAABWUUYAAIBVlBEAAGAVZQQAAFhFGQEAAFZRRgAAgFWUEQAAYBVlBAAAWEUZqWr5x2wnAADAq1BGqtrGWbYTAADgVSgjVa2k0HYCAAC8CmWkqp3i2jQAAJyOMlLV1r5gOwEAAF6FMgIAAKyijAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjAADAKsoIAACwijICAACsoozYUFxkOwEAAF6DMmJD2vu2EwAA4DUoIzacOGQ7AQAAXoMyAgAArKKM2HA43XYCAAC8BmXEho3/ZzsBAABegzICAACsoowAAACrKCMAAMAqyggAALCKMgIAAKyijAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjthScsJ0AAACvQBmxZet7thMAAOAVKCO2lBTZTgAAgFegjNhyNMN2AgAAvAJlxJaUl20nAADAK1BGAACAVZQRAABgFWUEAABYRRkBAABWUUYAAIBVlBEAAGAVZQQAAFhFGbGp8JTtBAAAWEcZsWn7B7YTAABgHWXEpuIC2wkAALCOMmJT9g7bCQAAsI4yYtOGN2wnAADAOsoIAACwijICAACsoowAAACrKCMAAMAqyggAALCKMgIAAKyijAAAAKvKXUZWr16tAQMGqEmTJnI4HFq4cOEFn7Ny5UpdeeWVCggIUKtWrTR79uwKRK2hTh61nQAAAKvKXUaOHz+uTp06acaMGWUan56erv79++vaa69Vamqqxo4dq1GjRmnp0qXlDlsj7VpkOwEAAFb5lfcJ/fr1U79+/co8fubMmWrRooWmTZsmSWrfvr3WrFmj559/XgkJCeXdfM1z8ojtBAAAWOXxY0ZSUlIUHx/vtiwhIUEpKSnnfE5+fr5yc3PdbjXWp4/YTgAAgFUeLyNZWVmKjIx0WxYZGanc3FydPHnyrM9JSkpSeHi46xYTE+PpmAAAwBKv/DTNhAkTlJOT47rt27fPdiQAAOAh5T5mpLyioqKUnZ3ttiw7O1thYWEKCgo663MCAgIUEBDg6WgAAMALeHzPSFxcnJYvX+62LDk5WXFxcZ7eNAAAqAbKXUby8vKUmpqq1NRUSc6P7qampiojI0OS8y2W4cOHu8bfeeed+u677/Tggw9q165deuWVV/T+++/r3nvvrZwZAACAaq3cZWTjxo3q0qWLunTpIkkaN26cunTpokmTJkmSMjMzXcVEklq0aKHFixcrOTlZnTp10rRp0/Tmm2/ysd7TlZTYTgAAgDUOY4yxHeJCcnNzFR4erpycHIWFhVXeiqeEV966Lsaf35faUM4AADVLWX9/e+WnaWqdE4dsJwAAwBrKiDdY+6LtBAAAWEMZ8QY/7bSdAAAAaygjAADAKsoIAACwijICAACsoowAAACrKCMAAMAqyoi32LfedgIAAKygjHiLnB9sJwAAwArKiLfYNNt2AgAArKCMeIv0VbYTAABgBWUEAABYRRkBAABWUUYAAIBVlBFvkp9nOwEAAFWOMuJNts2xnQAAgCpHGfEmi++znQAAgCpHGQEAAFZRRgAAgFWUEQAAYBVlxNsUF9pOAABAlaKMeJvvOC08AKB2oYx4m6/m204AAECVoox4m9R3bCcAAKBKUUYAAIBVlBEAAGAVZQQAAFhFGfFG2V/ZTgAAQJWhjHij/am2EwAAUGUoI97ow/+1nQAAgCpDGQEAAFZRRgAAgFWUEW91ZK/tBAAAVAnKiLda8aTtBAAAVAnKiLfaNtd2AgAAqgRlBAAAWEUZ8WZFBbYTAADgcZQRb/afu20nAADA4ygj3mzre7YTAADgcZQRAABgFWUEAABYRRnxdjk/2k4AAIBHUUa83Rev2E4AAIBHUUa8XcrLthMAAOBRlBEAAGAVZQQAAFhFGakODn9nOwEAAB5DGakOXuwiFRfZTgEAgEdQRqqLBX+1nQAAAI+gjFQX2z+wnQAAAI+gjFQnxw/ZTgAAQKWjjFQnz7S0nQAAgEpHGQEAAFZRRqobY2wnAACgUlFGqpu0ebYTAABQqSgj1c3826WSYtspAACoNJSR6mjxONsJAACoNJSR6mjTbNsJAACoNJQRAABgFWWkuso7YDsBAACVokJlZMaMGWrevLkCAwPVs2dPrV+//pxjZ8+eLYfD4XYLDAyscGD81we32U4AAEClKHcZmTt3rsaNG6fJkydr8+bN6tSpkxISEnTgwLn/px4WFqbMzEzXbe/evRcVGpK+/1xa+rDtFAAAXLRyl5HnnntOt99+u2699VZ16NBBM2fOVHBwsN56661zPsfhcCgqKsp1i4yMvKjQ+K+UlzkJGgCg2itXGSkoKNCmTZsUHx//8wp8fBQfH6+UlJRzPi8vL0+XXnqpYmJiNHDgQH311VcVTwx3b99gOwEAABelXGXk4MGDKi4uPmPPRmRkpLKyss76nLZt2+qtt97Shx9+qH/9618qKSlRr1699MMPP5xzO/n5+crNzXW74RzSV0uncmynAACgwjz+aZq4uDgNHz5cnTt3Vp8+fTR//nw1atRIr7322jmfk5SUpPDwcNctJibG0zGrt6nNpKJ82ykAAKiQcpWRhg0bytfXV9nZ2W7Ls7OzFRUVVaZ11KlTR126dNE333xzzjETJkxQTk6O67Zv377yxKydnmhsOwEAABVSrjLi7++vrl27avny5a5lJSUlWr58ueLi4sq0juLiYqWlpSk6OvqcYwICAhQWFuZ2Qxm8+ivbCQAAKDe/8j5h3LhxGjFihLp166YePXpo+vTpOn78uG699VZJ0vDhw9W0aVMlJSVJkh577DFdddVVatWqlY4ePapnnnlGe/fu1ahRoyp3JpCy06SSEsmHc9kBAKqPcpeRIUOG6KefftKkSZOUlZWlzp0765NPPnEd1JqRkSGf034ZHjlyRLfffruysrJUr149de3aVevWrVOHDh0qbxb42epnpGvG204BAECZOYzx/hNV5ObmKjw8XDk5OZX7ls2U8MpblzeZwqdrAAD2lfX3N/vza6KaWrIAADUSZaSmOnnEdgIAAMqEMlJTPd1cyvnRdgoAAC6IMlKTPd9BWvui7RQAAJwXZaSmS57IMSQAAK9GGaktjh+0nQAAgLOijNQWz1xmOwEAAGdFGalNpoRLe5bZTgEAgBvKSG3zzk22EwAA4IYyUhs911EqLrSdAgAASZSR2in3B+m1PrZTAAAgiTJSex34ynYCAAAkUUZqtynhztv+VNtJAAC1GGUE0ut9pHUv2U4BAKilKCNw+vQRaeVU2ykAALUQZQQ/W5nkfNvmHzdIxw/ZTgMAqCUoIzhT+irpmZZS4SnbSQAAtQBlBOf2YaJUeNJ2CgBADednOwC82PYPnDdJmpJjNwsAoMaijKBspoSf9jXFBABQeXibBuU3JVzav8V2CgBADUEZQcW8fg3HkwAAKgVlBBX3ZJRzL8m3n9lOAgCoxjhmBBfvnzf+/HXiBqlRG3tZAADVDntGULlmdHfuLfnsSdtJAADVBGUEnrH671LaB5IxtpMAALwcZQSe8++R0qMRzj0lxYW20wAAvBTHjKBqPN7Q+WdIlHT/brtZAABehT0jqFp5Wc49JdPaS1vnSvP/KpUU204FALCIPSOw49h+acEdzq+3zXH+OW6nFNbEXiYAgBXsGYH3eK69c6/Jqr/bTgIAqEKUEXifFU86S8nedbaTAACqAG/TwHvN6uf8M7qzlJn68/KwptKYzVKdQBupAACVjD0j8H6nFxFJyv1RejJSWvuCcw/KlHDp5BEr0QAAF48yguoredLPXz/dXFpwl3TyqPP+0QyppMRGKgBAOfE2DWqOre86b7/0t0zJP7jq8wAAyoQygprvqeifv/5bpnTioPPriGZ28gAA3FBGULucXkzOpvc90m8fk07lSL7+Up2gqskFALUYZQQ43doXnLfTDXlHatdfcjjsZAKAGo4yAlzI3GHOP3/ziPTZE86v+z8ndR9pLxMA1CAOY7z/Gu+5ubkKDw9XTk6OwsLCKm/FU8Irb13A6a74H2nQK86rFa94Quo2UqrfwnYqAKhSZf39zZ4RwBO2zfn5mjuStO4l558db5SC6knb5klD3pYu+43zI8ilbwHxVhCAWogyAlSlrxb8/PU/bzz3uEt/Je1dI/kFSQ9+K/nX9Xw2ALCEMgJ4o71rnH8WnZSeOsuVjDsMlK4YIp04JNVtLLXtW7X5AKASUUaA6mjHh85beYxMlmJ6SIWnpLT3pbbXS3UbeiYfAJQDZQSoLf7vt79YMObMMd1GShv/7+f7MT2lv8yXAkKcp9gPayr5+DqPc/HhahIAKgdlBMDPTi8ikrTvSympadme27CtVFIoJSRJfgHSPwdJwQ2l+3ZJvnWcnyz6doXU4tecTA6AG8oIgMpxcLfzz/eG/LzsxEHp8Qq+FdTu99LV90t1Gzn3yOzfLIVdIoVGOh8vLpJ8+ScMqAn4mwzAO+1a5LxVVMJTzk8v/bDBef/BdCm4fuVkA1CpKCMAaqalf3O///eLPOlcxxulfRuk3B+kVr+VcvdLB75ynjdmbJrk4+e8OXylY/ul0Gip8KTzY9klxc5jbUpxPhnADWUEAMri9HPEfJP889cnj0hJl3h223GjpY5/kLK3Sz9ulFr0kdr2cxafVU9LIY2dx+F8/JB0STfp5gXO43SAaoLTwQMAzu/ym6Tt/z77Yz3ukK6bJPmHOPf4HD/oLEKB5/j3NT9PSnnZuc6GrT2XGV6hrL+/KSMAgJojJErqeYdzT9K+9VJ0J6lBK+fBzsY4b5JkiqWC41JQhNW4NR3XpgEA1D55WdLyx5w3b9P819LJo1J2mvP+byZKwQ2kRWOd968cITW90nnNqjp1nccjyUglRZJPHeeep6/mO/c6tfzNuc/188vzABnj9ccpsWcEAIDarnWCNOz9Sl9tWX9/cwpFAABquz1LpSPfW9s8ZQQAAEh5P1nbNGUEAABY/Tg4ZQQAAEi+/tY2TRkBAADsGQEAAJZRRgAAgFU+1ayMzJgxQ82bN1dgYKB69uyp9evXn3f8vHnz1K5dOwUGBio2NlZLliypUFgAAOAh1emYkblz52rcuHGaPHmyNm/erE6dOikhIUEHDhw46/h169Zp6NChGjlypLZs2aJBgwZp0KBB2r59+0WHv1h986fqH0W/1fLiLlpU3FM/NrpaanmNdGlvqVE75xnwAACoDSy+TVPuM7D27NlT3bt318svvyxJKikpUUxMjMaMGaOHHnrojPFDhgzR8ePHtWjRIteyq666Sp07d9bMmTPLtE1PnYG1+UOLyzW+YUiA2keHalDnpqrj56N2UaGSpLoBfqof7K+C4hIF1fFVHV+HitPXyO/t31daVgAAPOpvmZJ/cKWu0iPXpikoKNCmTZs0YcIE1zIfHx/Fx8crJSXlrM9JSUnRuHHj3JYlJCRo4cKF5dm0VziYl6/P9+Tr8z0Hy/iMd93utXVk6C++y3Sz37LKDwcAwMWw+DZNucrIwYMHVVxcrMjISLflkZGR2rVr11mfk5WVddbxWVlZ59xOfn6+8vPzXfdzc3PLE9Nr7TbNNLHoNk0suk2P9G+vUb9u6XyguOjnCyd9/anzKpLffy7t/I+1rACAWsbH19qmvfKqvUlJSXr00Uc9vp3vp/aXJJ0qLFa7iZ94fHunu613i5/v+PpJTbo4vy79s+dfK3+jRQWS33mab+k7dg6H8+viQudltusE/Xzp7aJT0qkcyS/AeUVJU/LfK0r6SYe+dT4/oplUeML5WO6PUqP2UuFx5/P9ApxXrSw86Zx32CXSrkVSszjnXwT/EOmHDc7thsf8d+wJKbi+c9tH90knD0snDkkN20qHvpFa9nFmKjwpHdjhXB4YJvmHOq9uefBrKS9bKi5wPi//mNS4vXQsy/k/gfRV0qW9nMcK7U91vm+au186/pMUebm070vJ4eN8HZp2debM3iEd/lbau05qcJkzf/ZXzm206OPc1bk3xXmtBx9f55jQaCkjRcpKkxp3cG6jfkvn9nz9ncsKjjtfvw1vSkX5UsdBUs4+52sREintWux83fKPSYe/k2Kukk4dlRy+znERl0oNW0nHsqUDX0l1gp3fh7xsyS/QOY/CE1Ljjs5cJw47v0cOh3TFEOf38addzu99Zuq5f1Z8A5yXZQ8Mc34Pjv/iNNKNO0oBIdLJI87XX3J+PwqOnbmusEuk/FznrZTDx5lbcs674MTZn1uqTrBzXmfTtJtz7nvXuC8Pqu/8WTobv0Dnz5sbh/M/CiePnDsHLux8rzvsueFlq1f2LdcxIwUFBQoODtYHH3ygQYMGuZaPGDFCR48e1YcffnjGc5o1a6Zx48Zp7NixrmWTJ0/WwoULtXXr1rNu52x7RmJiYir/qr0AAMBjPHLVXn9/f3Xt2lXLly93LSspKdHy5csVFxd31ufExcW5jZek5OTkc46XpICAAIWFhbndAABAzVTut2nGjRunESNGqFu3burRo4emT5+u48eP69Zbb5UkDR8+XE2bNlVSUpIk6Z577lGfPn00bdo09e/fX3PmzNHGjRv1+uuvV+5MAABAtVTuMjJkyBD99NNPmjRpkrKystS5c2d98sknroNUMzIy5OPz8w6XXr166d1339Ujjzyiv/3tb2rdurUWLlyoyy+/vPJmAQAAqq1yn2fEBk+dZwQAAHiOR44ZAQAAqGyUEQAAYBVlBAAAWEUZAQAAVlFGAACAVZQRAABgFWUEAABYRRkBAABWUUYAAIBV5T4dvA2lJ4nNzc29wEgAAOAtSn9vX+hk79WijBw7dkySFBMTYzkJAAAor2PHjik8PPycj1eLa9OUlJRo//79Cg0NlcPhqLT15ubmKiYmRvv27auV17ypzfNn7rVz7lLtnj9zr51zl+zN3xijY8eOqUmTJm4X0f2larFnxMfHR5dcconH1h8WFlYrfzhL1eb5M/faOXepds+fudfOuUt25n++PSKlOIAVAABYRRkBAABW1eoyEhAQoMmTJysgIMB2FCtq8/yZe+2cu1S758/ca+fcJe+ff7U4gBUAANRctXrPCAAAsI8yAgAArKKMAAAAqygjAADAqlpdRmbMmKHmzZsrMDBQPXv21Pr1621HOq+kpCR1795doaGhaty4sQYNGqTdu3e7jTl16pQSExPVoEEDhYSE6KabblJ2drbbmIyMDPXv31/BwcFq3LixHnjgARUVFbmNWblypa688koFBASoVatWmj179hl5bL5+U6dOlcPh0NixY13LavLcf/zxR/3lL39RgwYNFBQUpNjYWG3cuNH1uDFGkyZNUnR0tIKCghQfH689e/a4rePw4cMaNmyYwsLCFBERoZEjRyovL89tzLZt2/TrX/9agYGBiomJ0d///vczssybN0/t2rVTYGCgYmNjtWTJEs9M+r+Ki4s1ceJEtWjRQkFBQbrsssv0+OOPu13roqbMf/Xq1RowYICaNGkih8OhhQsXuj3uTfMsS5bKnH9hYaHGjx+v2NhY1a1bV02aNNHw4cO1f//+GjH/C33vT3fnnXfK4XBo+vTpNWLupSutlebMmWP8/f3NW2+9Zb766itz++23m4iICJOdnW072jklJCSYWbNmme3bt5vU1FRz/fXXm2bNmpm8vDzXmDvvvNPExMSY5cuXm40bN5qrrrrK9OrVy/V4UVGRufzyy018fLzZsmWLWbJkiWnYsKGZMGGCa8x3331ngoODzbhx48yOHTvMSy+9ZHx9fc0nn3ziGmPz9Vu/fr1p3ry5ueKKK8w999xT4+d++PBhc+mll5pbbrnFfPnll+a7774zS5cuNd98841rzNSpU014eLhZuHCh2bp1q7nhhhtMixYtzMmTJ11j+vbtazp16mS++OIL8/nnn5tWrVqZoUOHuh7PyckxkZGRZtiwYWb79u3mvffeM0FBQea1115zjVm7dq3x9fU1f//7382OHTvMI488YurUqWPS0tI8MndjjHnyySdNgwYNzKJFi0x6erqZN2+eCQkJMS+88EKNm/+SJUvMww8/bObPn28kmQULFrg97k3zLEuWypz/0aNHTXx8vJk7d67ZtWuXSUlJMT169DBdu3Z1W0d1nf+Fvvel5s+fbzp16mSaNGlinn/++Roxd2OMqbVlpEePHiYxMdF1v7i42DRp0sQkJSVZTFU+Bw4cMJLMqlWrjDHOv6x16tQx8+bNc43ZuXOnkWRSUlKMMc4feB8fH5OVleUa8+qrr5qwsDCTn59vjDHmwQcfNB07dnTb1pAhQ0xCQoLrvq3X79ixY6Z169YmOTnZ9OnTx1VGavLcx48fb371q1+d8/GSkhITFRVlnnnmGdeyo0ePmoCAAPPee+8ZY4zZsWOHkWQ2bNjgGvPxxx8bh8NhfvzxR2OMMa+88oqpV6+e67Uo3Xbbtm1d9wcPHmz69+/vtv2ePXuav/71rxc3yfPo37+/ue2229yW/eEPfzDDhg0zxtTc+f/yF5I3zbMsWS7W+X4hl1q/fr2RZPbu3WuMqTnzP9fcf/jhB9O0aVOzfft2c+mll7qVkeo+91r5Nk1BQYE2bdqk+Ph41zIfHx/Fx8crJSXFYrLyycnJkSTVr19fkrRp0yYVFha6zatdu3Zq1qyZa14pKSmKjY1VZGSka0xCQoJyc3P11Vdfucacvo7SMaXrsPn6JSYmqn///mfkq8lz/+ijj9StWzf96U9/UuPGjdWlSxe98cYbrsfT09OVlZXllik8PFw9e/Z0m3tERIS6devmGhMfHy8fHx99+eWXrjFXX321/P393ea+e/duHTlyxDXmfK+PJ/Tq1UvLly/X119/LUnaunWr1qxZo379+kmq+fMv5U3zLEuWqpCTkyOHw6GIiAhX7po6/5KSEt1888164IEH1LFjxzMer+5zr5Vl5ODBgyouLnb7pSRJkZGRysrKspSqfEpKSjR27Fj17t1bl19+uSQpKytL/v7+rr+YpU6fV1ZW1lnnXfrY+cbk5ubq5MmT1l6/OXPmaPPmzUpKSjrjsZo89++++06vvvqqWrduraVLl+quu+7S3XffrX/84x9u2c+XKSsrS40bN3Z73M/PT/Xr16+U18eT3/eHHnpI//M//6N27dqpTp066tKli8aOHathw4a5Zaup8y/lTfMsSxZPO3XqlMaPH6+hQ4e6LvxWk+f/9NNPy8/PT3ffffdZH6/uc68WV+3FmRITE7V9+3atWbPGdpQqsW/fPt1zzz1KTk5WYGCg7ThVqqSkRN26ddNTTz0lSerSpYu2b9+umTNnasSIEZbTed7777+vd955R++++646duyo1NRUjR07Vk2aNKkV88eZCgsLNXjwYBlj9Oqrr9qO43GbNm3SCy+8oM2bN8vhcNiO4xG1cs9Iw4YN5evre8YnLbKzsxUVFWUpVdmNHj1aixYt0ooVK3TJJZe4lkdFRamgoEBHjx51G3/6vKKios4679LHzjcmLCxMQUFBVl6/TZs26cCBA7ryyivl5+cnPz8/rVq1Si+++KL8/PwUGRlZY+ceHR2tDh06uC1r3769MjIy3LKfL1NUVJQOHDjg9nhRUZEOHz5cKa+PJ//ePPDAA669I7Gxsbr55pt17733uvaQ1fT5l/KmeZYli6eUFpG9e/cqOTnZtVekNFdNnP/nn3+uAwcOqFmzZq5///bu3av77rtPzZs3d2WqznOvlWXE399fXbt21fLly13LSkpKtHz5csXFxVlMdn7GGI0ePVoLFizQZ599phYtWrg93rVrV9WpU8dtXrt371ZGRoZrXnFxcUpLS3P7oS39C136Cy8uLs5tHaVjStdh4/W77rrrlJaWptTUVNetW7duGjZsmOvrmjr33r17n/ER7q+//lqXXnqpJKlFixaKiopyy5Sbm6svv/zSbe5Hjx7Vpk2bXGM+++wzlZSUqGfPnq4xq1evVmFhoWtMcnKy2rZtq3r16rnGnO/18YQTJ07Ix8f9nypfX1+VlJRIqvnzL+VN8yxLFk8oLSJ79uzRsmXL1KBBA7fHa+r8b775Zm3bts3t378mTZrogQce0NKlS2vG3Ct86Gs1N2fOHBMQEGBmz55tduzYYe644w4TERHh9kkLb3PXXXeZ8PBws3LlSpOZmem6nThxwjXmzjvvNM2aNTOfffaZ2bhxo4mLizNxcXGux0s/3vq73/3OpKammk8++cQ0atTorB9vfeCBB8zOnTvNjBkzzvrxVtuv3+mfpjGm5s59/fr1xs/Pzzz55JNmz5495p133jHBwcHmX//6l2vM1KlTTUREhPnwww/Ntm3bzMCBA8/6kc8uXbqYL7/80qxZs8a0bt3a7WN/R48eNZGRkebmm28227dvN3PmzDHBwcFnfOzPz8/PPPvss2bnzp1m8uTJHv9o74gRI0zTpk1dH+2dP3++adiwoXnwwQdr3PyPHTtmtmzZYrZs2WIkmeeee85s2bLF9WkRb5pnWbJU5vwLCgrMDTfcYC655BKTmprq9m/g6Z8Oqa7zv9D3/pd++Wma6jx3Y2rxR3uNMeall14yzZo1M/7+/qZHjx7miy++sB3pvCSd9TZr1izXmJMnT5r//d//NfXq1TPBwcHmxhtvNJmZmW7r+f77702/fv1MUFCQadiwobnvvvtMYWGh25gVK1aYzp07G39/f9OyZUu3bZSy/fr9sozU5Ln/5z//MZdffrkJCAgw7dq1M6+//rrb4yUlJWbixIkmMjLSBAQEmOuuu87s3r3bbcyhQ4fM0KFDTUhIiAkLCzO33nqrOXbsmNuYrVu3ml/96lcmICDANG3a1EydOvWMLO+//75p06aN8ff3Nx07djSLFy+u/AmfJjc319xzzz2mWbNmJjAw0LRs2dI8/PDDbr+Aasr8V6xYcda/4yNGjPC6eZYlS2XOPz09/Zz/Bq5YsaLaz/9C3/tfOlsZqa5zN8YYhzGnncYQAACgitXKY0YAAID3oIwAAACrKCMAAMAqyggAALCKMgIAAKyijAAAAKsoIwAAwCrKCAAAsIoyAgAArKKMAAAAqygjAADAKsoIAACw6v8BYevF2A2wyksAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCNZ0dQHl2Yz"
      },
      "source": [
        "## Testing your model\n",
        "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction.\n",
        "\n",
        "If your accuracy is over 90%, great work, but see if you can push a bit further!\n",
        "If your accuracy is under 90%, you'll need to make improvements.\n",
        "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YtZsYoTBl2Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88732493-561f-4133-b9e0-d9473e392475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.975\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0\n",
        "accuracy = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images.requires_grad = True\n",
        "\n",
        "        logits = model(images)\n",
        "        batch_loss = criterion(logits, labels)\n",
        "\n",
        "        test_loss += batch_loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        probs = torch.exp(logits)\n",
        "        _, top_class = probs.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "print(f\"Test accuracy: {accuracy/len(test_loader):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JaFUr2Cl2Yz"
      },
      "source": [
        "## Improving your model\n",
        "\n",
        "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    momentum=momentum,\n",
        "    weight_decay=0.0005\n",
        "    )"
      ],
      "metadata": {
        "id": "4gKlH6wi_i0C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "steps = 0\n",
        "train_loss = 0\n",
        "print_every = 5\n",
        "\n",
        "train_loss_history = list()\n",
        "valid_loss_history = list()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images.requires_grad = True\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        train_loss_history.append(train_loss/len(train_loader))\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            valid_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    images.requires_grad = True\n",
        "\n",
        "                    logits = model(images)\n",
        "                    batch_loss = criterion(logits, labels)\n",
        "                    valid_loss += batch_loss.item()\n",
        "\n",
        "                    valid_loss_history.append(valid_loss/len(test_loader))\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    probs = torch.exp(logits)\n",
        "                    _, top_class = probs.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Training Loss: {train_loss/print_every:.3f}.. \"\n",
        "                  f\"Validation Loss: {valid_loss/len(test_loader):.3f}.. \"\n",
        "                  f\"Accuracy: {accuracy/len(test_loader):.3f}\")\n",
        "            train_loss = 0\n",
        "            model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a42131fe-1d13-4b1b-ec92-a140777c5cf4",
        "id": "HWteQKfl_rRI"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20.. Training Loss: 0.070.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.185.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.207.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.217.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.226.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.225.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.256.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.245.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.223.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.255.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.215.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.195.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.165.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.185.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.237.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.296.. Validation Loss: 0.077.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.202.. Validation Loss: 0.076.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.247.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.209.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.195.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.214.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.258.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.212.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.318.. Validation Loss: 0.076.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.268.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.231.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.243.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.219.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.288.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.261.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.273.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.272.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.255.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.238.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.259.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.204.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.197.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.233.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.208.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.235.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.245.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.215.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.213.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.268.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.240.. Validation Loss: 0.078.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.241.. Validation Loss: 0.078.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.299.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.206.. Validation Loss: 0.076.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.208.. Validation Loss: 0.076.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.237.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.263.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.260.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.208.. Validation Loss: 0.077.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.223.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.273.. Validation Loss: 0.074.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.245.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.216.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.269.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.182.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.222.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.213.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.229.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.201.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.210.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.215.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.246.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.234.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.206.. Validation Loss: 0.074.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.223.. Validation Loss: 0.074.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.218.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.202.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.242.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.266.. Validation Loss: 0.073.. Accuracy: 0.977\n",
            "Epoch 1/20.. Training Loss: 0.195.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.237.. Validation Loss: 0.073.. Accuracy: 0.977\n",
            "Epoch 1/20.. Training Loss: 0.219.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.188.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.215.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.238.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.222.. Validation Loss: 0.077.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.268.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.208.. Validation Loss: 0.075.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.222.. Validation Loss: 0.074.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.217.. Validation Loss: 0.075.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.230.. Validation Loss: 0.077.. Accuracy: 0.973\n",
            "Epoch 1/20.. Training Loss: 0.191.. Validation Loss: 0.076.. Accuracy: 0.973\n",
            "Epoch 1/20.. Training Loss: 0.249.. Validation Loss: 0.074.. Accuracy: 0.974\n",
            "Epoch 1/20.. Training Loss: 0.221.. Validation Loss: 0.072.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.207.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.213.. Validation Loss: 0.072.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.216.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 1/20.. Training Loss: 0.207.. Validation Loss: 0.076.. Accuracy: 0.975\n",
            "Epoch 1/20.. Training Loss: 0.247.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.215.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.210.. Validation Loss: 0.076.. Accuracy: 0.974\n",
            "Epoch 2/20.. Training Loss: 0.228.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.258.. Validation Loss: 0.075.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.244.. Validation Loss: 0.074.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.185.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.245.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.214.. Validation Loss: 0.074.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.219.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.219.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.180.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.243.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.184.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.212.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.235.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.224.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.256.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.183.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.290.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.196.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.226.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.194.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.207.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.175.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.250.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.168.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.254.. Validation Loss: 0.074.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.219.. Validation Loss: 0.075.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.243.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.184.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.254.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.212.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.201.. Validation Loss: 0.071.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.230.. Validation Loss: 0.071.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.239.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.211.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.208.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.168.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.160.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.214.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.252.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.238.. Validation Loss: 0.071.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.195.. Validation Loss: 0.071.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.186.. Validation Loss: 0.071.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.297.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.218.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.247.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.194.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.264.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.188.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.234.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.154.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.185.. Validation Loss: 0.072.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.263.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.210.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.217.. Validation Loss: 0.070.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.253.. Validation Loss: 0.070.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.279.. Validation Loss: 0.071.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.257.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.201.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.241.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.195.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.183.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.247.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.169.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.226.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.204.. Validation Loss: 0.070.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.213.. Validation Loss: 0.072.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.237.. Validation Loss: 0.072.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.175.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.202.. Validation Loss: 0.070.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.215.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.196.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.250.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.221.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.224.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.205.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.158.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.241.. Validation Loss: 0.070.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.177.. Validation Loss: 0.073.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.232.. Validation Loss: 0.073.. Accuracy: 0.975\n",
            "Epoch 2/20.. Training Loss: 0.208.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.211.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.197.. Validation Loss: 0.069.. Accuracy: 0.976\n",
            "Epoch 2/20.. Training Loss: 0.206.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.274.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.230.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.206.. Validation Loss: 0.067.. Accuracy: 0.977\n",
            "Epoch 2/20.. Training Loss: 0.176.. Validation Loss: 0.067.. Accuracy: 0.979\n",
            "Epoch 2/20.. Training Loss: 0.207.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.235.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.217.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.155.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 2/20.. Training Loss: 0.237.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.145.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.183.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.229.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.209.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.215.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.224.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.167.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.196.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.189.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.209.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.246.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.193.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.166.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.241.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.230.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.166.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.207.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.217.. Validation Loss: 0.067.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.261.. Validation Loss: 0.067.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.206.. Validation Loss: 0.068.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.162.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.221.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.208.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.228.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.222.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.223.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.232.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.201.. Validation Loss: 0.069.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.206.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.177.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.193.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.208.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.199.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.275.. Validation Loss: 0.070.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.191.. Validation Loss: 0.071.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.199.. Validation Loss: 0.070.. Accuracy: 0.976\n",
            "Epoch 3/20.. Training Loss: 0.175.. Validation Loss: 0.070.. Accuracy: 0.976\n",
            "Epoch 3/20.. Training Loss: 0.249.. Validation Loss: 0.070.. Accuracy: 0.976\n",
            "Epoch 3/20.. Training Loss: 0.229.. Validation Loss: 0.070.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.221.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.198.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.197.. Validation Loss: 0.067.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.236.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.251.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.219.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.202.. Validation Loss: 0.070.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.217.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.151.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.132.. Validation Loss: 0.067.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.164.. Validation Loss: 0.069.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.222.. Validation Loss: 0.067.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.221.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.196.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.216.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.187.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.284.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.200.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.184.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.243.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.141.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.203.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.180.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.225.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.195.. Validation Loss: 0.067.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.211.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.155.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.225.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.264.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.234.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.264.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.212.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.174.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.192.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.217.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.225.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.211.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.192.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.228.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.196.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.184.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.195.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.205.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.159.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.217.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 3/20.. Training Loss: 0.229.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.193.. Validation Loss: 0.068.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.207.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.205.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.213.. Validation Loss: 0.068.. Accuracy: 0.977\n",
            "Epoch 3/20.. Training Loss: 0.202.. Validation Loss: 0.067.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.232.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.198.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 3/20.. Training Loss: 0.154.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.204.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.190.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.194.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.213.. Validation Loss: 0.064.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.201.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.260.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.231.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.173.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.236.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.224.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.229.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.201.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.126.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.146.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.206.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.149.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.217.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.224.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.169.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.225.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.221.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.192.. Validation Loss: 0.066.. Accuracy: 0.977\n",
            "Epoch 4/20.. Training Loss: 0.186.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.179.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.167.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.172.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.194.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.174.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.169.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.178.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.236.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.157.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.184.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.222.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.218.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.156.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.176.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.232.. Validation Loss: 0.062.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.200.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.165.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.237.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.179.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.224.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.214.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.219.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.165.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.219.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.148.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.215.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.214.. Validation Loss: 0.066.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.155.. Validation Loss: 0.065.. Accuracy: 0.978\n",
            "Epoch 4/20.. Training Loss: 0.247.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.222.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.186.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.176.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.192.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.198.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.138.. Validation Loss: 0.066.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.217.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.196.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.206.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.206.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.194.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.176.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.267.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.200.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.184.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.174.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.195.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.278.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.196.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.247.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.214.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.231.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.238.. Validation Loss: 0.063.. Accuracy: 0.981\n",
            "Epoch 4/20.. Training Loss: 0.235.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.163.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.223.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.187.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.224.. Validation Loss: 0.065.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.208.. Validation Loss: 0.065.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.176.. Validation Loss: 0.065.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.203.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.206.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.208.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.187.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.193.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.162.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.220.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.208.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.206.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 4/20.. Training Loss: 0.183.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.176.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 4/20.. Training Loss: 0.222.. Validation Loss: 0.063.. Accuracy: 0.978\n",
            "Epoch 5/20.. Training Loss: 0.154.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.225.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.193.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.147.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.177.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.186.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.154.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.209.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.176.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.197.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.180.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.216.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.218.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.210.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.222.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.171.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.146.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.220.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.205.. Validation Loss: 0.064.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.218.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.261.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.177.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.189.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.230.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.217.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.152.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.217.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.171.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.206.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.200.. Validation Loss: 0.064.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.217.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.170.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.191.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.168.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.170.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.194.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.259.. Validation Loss: 0.063.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.164.. Validation Loss: 0.063.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.207.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.225.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.214.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.259.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.195.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.214.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.217.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.172.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.204.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.206.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.161.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.219.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.177.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.197.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.223.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.195.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.209.. Validation Loss: 0.063.. Accuracy: 0.979\n",
            "Epoch 5/20.. Training Loss: 0.183.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.245.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.210.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.199.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.162.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.199.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.163.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.195.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.179.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.223.. Validation Loss: 0.060.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.168.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.204.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.225.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.216.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.192.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.161.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.207.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.205.. Validation Loss: 0.060.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.156.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.162.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.232.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.227.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.268.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.171.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.180.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.182.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.196.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.186.. Validation Loss: 0.062.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.215.. Validation Loss: 0.061.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.210.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.190.. Validation Loss: 0.061.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.208.. Validation Loss: 0.063.. Accuracy: 0.980\n",
            "Epoch 5/20.. Training Loss: 0.170.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.187.. Validation Loss: 0.062.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.171.. Validation Loss: 0.060.. Accuracy: 0.982\n",
            "Epoch 5/20.. Training Loss: 0.179.. Validation Loss: 0.060.. Accuracy: 0.982\n",
            "Epoch 5/20.. Training Loss: 0.159.. Validation Loss: 0.060.. Accuracy: 0.982\n",
            "Epoch 5/20.. Training Loss: 0.175.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 5/20.. Training Loss: 0.165.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.161.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.205.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.249.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.213.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.186.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.144.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.191.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.204.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.173.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.241.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.183.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.166.. Validation Loss: 0.059.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.152.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.217.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.169.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.157.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.161.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.250.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.162.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.203.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.199.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.191.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.156.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.166.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.161.. Validation Loss: 0.060.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.213.. Validation Loss: 0.060.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.199.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.202.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.215.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.210.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.166.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.184.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.159.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.218.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.181.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.175.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.207.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.178.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.174.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.203.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.176.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.162.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.184.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.186.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.176.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.165.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.181.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.171.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.155.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.211.. Validation Loss: 0.060.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.169.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.165.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.226.. Validation Loss: 0.058.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.179.. Validation Loss: 0.058.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.177.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.204.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.171.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.178.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.197.. Validation Loss: 0.059.. Accuracy: 0.980\n",
            "Epoch 6/20.. Training Loss: 0.138.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.183.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.232.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.167.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.167.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.199.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.202.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.189.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.182.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.217.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.193.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.219.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.172.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.170.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.219.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.196.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.186.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.157.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.186.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.184.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.171.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.169.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.161.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.230.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.151.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.183.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.193.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.177.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.141.. Validation Loss: 0.059.. Accuracy: 0.982\n",
            "Epoch 6/20.. Training Loss: 0.139.. Validation Loss: 0.059.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.231.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.178.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.148.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 6/20.. Training Loss: 0.222.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.179.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.204.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.189.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.183.. Validation Loss: 0.057.. Accuracy: 0.980\n",
            "Epoch 7/20.. Training Loss: 0.172.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.192.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.205.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.177.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.163.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.219.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.175.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.197.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.228.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.180.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.206.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.169.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.149.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.232.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.202.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.205.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.172.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.172.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.160.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.188.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.216.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.178.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.190.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.221.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.139.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.155.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.152.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.138.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.186.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.188.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.199.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.173.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.215.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.147.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.167.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.206.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.173.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.218.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.154.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.173.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.187.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.163.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.149.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.220.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.202.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.160.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.168.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.139.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.142.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.183.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.209.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.164.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.243.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.146.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.175.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.196.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.226.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.173.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.134.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.192.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.235.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.166.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.170.. Validation Loss: 0.057.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.192.. Validation Loss: 0.058.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.173.. Validation Loss: 0.058.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.145.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.126.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.170.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.194.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.182.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.157.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.218.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.184.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.171.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.229.. Validation Loss: 0.057.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.202.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.159.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.158.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.103.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.181.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.184.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.190.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.184.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.182.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.157.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.149.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 7/20.. Training Loss: 0.211.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 7/20.. Training Loss: 0.160.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.193.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 7/20.. Training Loss: 0.140.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.147.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.191.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.186.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.123.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.191.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.207.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.180.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.156.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.202.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.136.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.187.. Validation Loss: 0.054.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.216.. Validation Loss: 0.054.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.159.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.186.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.185.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.236.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.198.. Validation Loss: 0.056.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.151.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.160.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.162.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.176.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.210.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.186.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.210.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.154.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.210.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.166.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.199.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.187.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.175.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.200.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.171.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.175.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.140.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.168.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.176.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.175.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.192.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.137.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.209.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.191.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.157.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.228.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.124.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.181.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.119.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.177.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.178.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.146.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.199.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.221.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.149.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.161.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.159.. Validation Loss: 0.055.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.150.. Validation Loss: 0.056.. Accuracy: 0.981\n",
            "Epoch 8/20.. Training Loss: 0.207.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.186.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.206.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.176.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.192.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.204.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.177.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.160.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.203.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.181.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.151.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.190.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.180.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.162.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.144.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.221.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.158.. Validation Loss: 0.055.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.188.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.183.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.184.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.161.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.174.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.240.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.147.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.214.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.175.. Validation Loss: 0.054.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.156.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.141.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.175.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 8/20.. Training Loss: 0.139.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.128.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.171.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.145.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.230.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.165.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.149.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 8/20.. Training Loss: 0.177.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 8/20.. Training Loss: 0.176.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.169.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.164.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.208.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.165.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.178.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.177.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.199.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.191.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.152.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.142.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.189.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.140.. Validation Loss: 0.056.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.172.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.244.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.250.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.172.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.177.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.197.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.166.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.184.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.198.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.197.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.163.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.196.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.158.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.158.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.160.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.180.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.175.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.142.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.191.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.174.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.210.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.174.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.198.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.181.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.186.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.167.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.178.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.153.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.171.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.182.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.185.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.195.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.154.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.174.. Validation Loss: 0.053.. Accuracy: 0.982\n",
            "Epoch 9/20.. Training Loss: 0.150.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.175.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.141.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.150.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.126.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.141.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.150.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.159.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.147.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.145.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.119.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.161.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.180.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.180.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.171.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.164.. Validation Loss: 0.054.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.166.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.175.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.142.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.211.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.138.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.184.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.169.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.147.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.116.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.276.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.185.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.151.. Validation Loss: 0.053.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.169.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.161.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.197.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.138.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.184.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.187.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.188.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.138.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.154.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.132.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.209.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.171.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 9/20.. Training Loss: 0.154.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.181.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.164.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.132.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.133.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.172.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.160.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 9/20.. Training Loss: 0.166.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.148.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.215.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.187.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.152.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.184.. Validation Loss: 0.051.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.214.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.165.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.155.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.179.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.156.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.201.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.153.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.231.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.162.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.196.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.155.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.185.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.155.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.166.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.179.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.141.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.199.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.165.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.164.. Validation Loss: 0.055.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.172.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.167.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.127.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.182.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.152.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.177.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.124.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.165.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.149.. Validation Loss: 0.053.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.146.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.186.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.181.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.237.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.185.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.156.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.144.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.195.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.160.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.142.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.166.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.182.. Validation Loss: 0.054.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.214.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.167.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.211.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.174.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.189.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.184.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.198.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.164.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.176.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.148.. Validation Loss: 0.051.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.188.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.162.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.186.. Validation Loss: 0.052.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.179.. Validation Loss: 0.052.. Accuracy: 0.982\n",
            "Epoch 10/20.. Training Loss: 0.140.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.144.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.208.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.218.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.173.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.201.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.147.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.180.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.192.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.216.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 10/20.. Training Loss: 0.181.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.191.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.187.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 10/20.. Training Loss: 0.147.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.187.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.203.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.160.. Validation Loss: 0.052.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.185.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.166.. Validation Loss: 0.050.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.127.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.169.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.117.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 10/20.. Training Loss: 0.230.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.213.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.155.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.170.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.201.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 10/20.. Training Loss: 0.148.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.177.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 10/20.. Training Loss: 0.141.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.168.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 11/20.. Training Loss: 0.195.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.182.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.157.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.199.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.170.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.133.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.157.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.141.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.168.. Validation Loss: 0.051.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.160.. Validation Loss: 0.052.. Accuracy: 0.983\n",
            "Epoch 11/20.. Training Loss: 0.132.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 11/20.. Training Loss: 0.163.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.190.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.135.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.178.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.132.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.151.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.191.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.185.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.143.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.174.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.142.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.120.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.180.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.983\n",
            "Epoch 11/20.. Training Loss: 0.218.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.145.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.160.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.196.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.177.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.152.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.136.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.200.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.206.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.200.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.186.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.174.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.183.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.219.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.178.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.133.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.148.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.162.. Validation Loss: 0.048.. Accuracy: 0.986\n",
            "Epoch 11/20.. Training Loss: 0.145.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.175.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.186.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.168.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.193.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.198.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.147.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 11/20.. Training Loss: 0.144.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.130.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.189.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.123.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.166.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.202.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.167.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.135.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 11/20.. Training Loss: 0.120.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.174.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.197.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.164.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.148.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.130.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.152.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.134.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.194.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.198.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.165.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.161.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.155.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.139.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.177.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.136.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.161.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.144.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.152.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.178.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.205.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 11/20.. Training Loss: 0.138.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.184.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.175.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.178.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.163.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.148.. Validation Loss: 0.051.. Accuracy: 0.983\n",
            "Epoch 11/20.. Training Loss: 0.134.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.183.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 11/20.. Training Loss: 0.160.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.149.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.160.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.135.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.161.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.170.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.191.. Validation Loss: 0.050.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.177.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.164.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.139.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.178.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.170.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.179.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.130.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.185.. Validation Loss: 0.049.. Accuracy: 0.983\n",
            "Epoch 12/20.. Training Loss: 0.156.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.222.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.161.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.161.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.179.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.194.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.155.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.159.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.167.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.159.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.146.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.188.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.191.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.215.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.222.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.138.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.143.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.161.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.150.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.194.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.152.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.172.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.149.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.150.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.191.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.218.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.139.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.182.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.159.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.172.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.175.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.162.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.161.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.155.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.132.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.088.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.125.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.169.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.125.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.153.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.156.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.183.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.122.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.169.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.164.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.150.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.138.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.136.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.138.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.149.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.154.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.096.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.145.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.203.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.165.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.154.. Validation Loss: 0.050.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.174.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.156.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.157.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.164.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.181.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.150.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.173.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.139.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.182.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.199.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.119.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.194.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.206.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.167.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.173.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.115.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.156.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.168.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.116.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 12/20.. Training Loss: 0.132.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 12/20.. Training Loss: 0.192.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.147.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.149.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.143.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.123.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.158.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.153.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.172.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.117.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.190.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.142.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.205.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.134.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.125.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.183.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.150.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.120.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.187.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.172.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.165.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.178.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.167.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.156.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.137.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.164.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.126.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.106.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.198.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.111.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.176.. Validation Loss: 0.048.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.151.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.199.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.141.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.124.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.134.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.151.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.186.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.201.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.165.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.142.. Validation Loss: 0.049.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.157.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.122.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.127.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.194.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.165.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.167.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.158.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.135.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.142.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.128.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.164.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.175.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.154.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.210.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.119.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.182.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.131.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.158.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.100.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.250.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.135.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.140.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.156.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.163.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.143.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.198.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.165.. Validation Loss: 0.047.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.180.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.137.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 13/20.. Training Loss: 0.207.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.158.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.197.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.166.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.147.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.174.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.124.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.166.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.179.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.107.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.123.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.169.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.125.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.184.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.138.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.131.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.176.. Validation Loss: 0.048.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.133.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 13/20.. Training Loss: 0.147.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.171.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.160.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.142.. Validation Loss: 0.049.. Accuracy: 0.984\n",
            "Epoch 13/20.. Training Loss: 0.140.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 14/20.. Training Loss: 0.210.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.126.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.149.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.197.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.154.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.221.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.162.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.134.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.146.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.146.. Validation Loss: 0.048.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.121.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.179.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.108.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.156.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.194.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 14/20.. Training Loss: 0.166.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.141.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.125.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.136.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.166.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.134.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.132.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.158.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.164.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.158.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.173.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.151.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.144.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.152.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.146.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.143.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.143.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.142.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.119.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.139.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.149.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.192.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.176.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.119.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.178.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.199.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.175.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.115.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.183.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.148.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.135.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.117.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.135.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.126.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.134.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.142.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.153.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.149.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.137.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.149.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.121.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.183.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.112.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.163.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.115.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.177.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.145.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.175.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.146.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.133.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.113.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.145.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.123.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.171.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 14/20.. Training Loss: 0.109.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.176.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.137.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.154.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.174.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.164.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.160.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.139.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.159.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.106.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.194.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.210.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.117.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.194.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.167.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.156.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 14/20.. Training Loss: 0.173.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.127.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.146.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 14/20.. Training Loss: 0.148.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.177.. Validation Loss: 0.047.. Accuracy: 0.984\n",
            "Epoch 15/20.. Training Loss: 0.136.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.151.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.156.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.138.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.193.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.117.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.149.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.169.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.136.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.159.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.136.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.134.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.147.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.148.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.148.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.114.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.155.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.172.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.216.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.121.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.142.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.119.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.172.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.154.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.136.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.125.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.124.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.124.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.168.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.159.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.145.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.143.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.181.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.185.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.126.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.140.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.191.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.188.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.147.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.198.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.154.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.143.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.184.. Validation Loss: 0.047.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.155.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.189.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.173.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.109.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.163.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.181.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.133.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.129.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.153.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.140.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.171.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.157.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.155.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.141.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 15/20.. Training Loss: 0.132.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 15/20.. Training Loss: 0.156.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.151.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.144.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.124.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.156.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.165.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.150.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.139.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.111.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.121.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.134.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.105.. Validation Loss: 0.046.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.171.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.130.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.205.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.211.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.171.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.116.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.177.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.107.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.153.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.169.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.154.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.113.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.173.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.109.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.140.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.152.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.180.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.149.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.202.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.179.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 15/20.. Training Loss: 0.144.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.145.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 15/20.. Training Loss: 0.160.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.162.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.142.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.177.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.175.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.157.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.130.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.141.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.123.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.165.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.144.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.145.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.176.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.163.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.138.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.147.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.172.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.133.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.147.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.190.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.119.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.159.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.128.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.174.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.131.. Validation Loss: 0.045.. Accuracy: 0.984\n",
            "Epoch 16/20.. Training Loss: 0.150.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.130.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.179.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.170.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.162.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.154.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.170.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.189.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.093.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.152.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.185.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.120.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.212.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.169.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.137.. Validation Loss: 0.045.. Accuracy: 0.987\n",
            "Epoch 16/20.. Training Loss: 0.162.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.129.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.137.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.129.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.110.. Validation Loss: 0.046.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.130.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.212.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.151.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.138.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.161.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.121.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.188.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.138.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.136.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.118.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.180.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.143.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.193.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.191.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.181.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.110.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.155.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.141.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.124.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.127.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.139.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.189.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.151.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.135.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.130.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.147.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 16/20.. Training Loss: 0.149.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.162.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.126.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.160.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.122.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.184.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.180.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.144.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.172.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.155.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 16/20.. Training Loss: 0.171.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 16/20.. Training Loss: 0.146.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 16/20.. Training Loss: 0.150.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.130.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.146.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 16/20.. Training Loss: 0.163.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.196.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.096.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.148.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.110.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.161.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.125.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 16/20.. Training Loss: 0.120.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.110.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.164.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.168.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.135.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.127.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.106.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.170.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.140.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.134.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.178.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.181.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.162.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.130.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.203.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.130.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.164.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.143.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.137.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.146.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.135.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.127.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.181.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.150.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.151.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.136.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.138.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.096.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.119.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.108.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.113.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.122.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.134.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.156.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.171.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.167.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.128.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.125.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.169.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.135.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.123.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.150.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.128.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.161.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.147.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.121.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.150.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.142.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.151.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.130.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.186.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.156.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.137.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.186.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.137.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.161.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.135.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.225.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.180.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.109.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.125.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.173.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.124.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.135.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.104.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.121.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.175.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.128.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.153.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.115.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.189.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.187.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 17/20.. Training Loss: 0.124.. Validation Loss: 0.045.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.223.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.172.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.127.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.161.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.165.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.116.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.143.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.172.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.167.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.141.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.176.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.124.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.136.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.133.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.147.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.154.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.126.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.189.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 17/20.. Training Loss: 0.144.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.127.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.157.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 17/20.. Training Loss: 0.171.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.157.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.157.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.159.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.146.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.159.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.161.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.166.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.126.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.135.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.144.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.121.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.136.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.111.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.174.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.145.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.121.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.148.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.119.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.122.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.122.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 18/20.. Training Loss: 0.099.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.156.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.137.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.156.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.142.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.185.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.126.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.151.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.165.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.147.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.160.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.132.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.181.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.111.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.172.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.121.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.152.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.166.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.157.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.149.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.124.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.126.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 18/20.. Training Loss: 0.121.. Validation Loss: 0.045.. Accuracy: 0.985\n",
            "Epoch 18/20.. Training Loss: 0.110.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.087.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.149.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.161.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.132.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.122.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.189.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.116.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.141.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.143.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.120.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.140.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.153.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.181.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.150.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.151.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.154.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.185.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.177.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.103.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.131.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.157.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.144.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.179.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.135.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.138.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.196.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.126.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.139.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.158.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.179.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.103.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.137.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.136.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.146.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.122.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.115.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.113.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.126.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.129.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.167.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.156.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.144.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.151.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.128.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.172.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.160.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 18/20.. Training Loss: 0.160.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.130.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 18/20.. Training Loss: 0.145.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.144.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.162.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.157.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.146.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.124.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.129.. Validation Loss: 0.040.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.090.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.112.. Validation Loss: 0.040.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.132.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.116.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.181.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.117.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.116.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.204.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.137.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.094.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.155.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.104.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.106.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.148.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.112.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.125.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.148.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.142.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.107.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.076.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.180.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.155.. Validation Loss: 0.044.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.159.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.168.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.153.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.164.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.142.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.106.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.126.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.133.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.144.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.137.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.122.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.132.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.121.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.163.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.170.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.120.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.147.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.128.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.193.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.104.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.162.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.108.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.143.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.132.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.172.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.109.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.136.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.141.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.131.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.165.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.126.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.123.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.172.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.129.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.108.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.128.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.162.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.166.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.144.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.146.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.152.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.160.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.167.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.145.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.143.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.145.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.113.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.143.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.099.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.164.. Validation Loss: 0.041.. Accuracy: 0.988\n",
            "Epoch 19/20.. Training Loss: 0.111.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.166.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.117.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.179.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.161.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.153.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.159.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.169.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.172.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 19/20.. Training Loss: 0.178.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 19/20.. Training Loss: 0.125.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.133.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.123.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.134.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.125.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.111.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.120.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.139.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.106.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.111.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.128.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.130.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.173.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.128.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.121.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.149.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.113.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.212.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.131.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.149.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.134.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.144.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.166.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.153.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.174.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.199.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.122.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.153.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.117.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.122.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.125.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.090.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.185.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.168.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.172.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.171.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.142.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.180.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.137.. Validation Loss: 0.042.. Accuracy: 0.985\n",
            "Epoch 20/20.. Training Loss: 0.167.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.146.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.148.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.134.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.142.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.123.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.148.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.114.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.135.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.139.. Validation Loss: 0.043.. Accuracy: 0.985\n",
            "Epoch 20/20.. Training Loss: 0.139.. Validation Loss: 0.043.. Accuracy: 0.985\n",
            "Epoch 20/20.. Training Loss: 0.125.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.138.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.148.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.124.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.152.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.206.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.149.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.139.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.116.. Validation Loss: 0.043.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.116.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.155.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.137.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.188.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.147.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.183.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.113.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.133.. Validation Loss: 0.044.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.139.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 20/20.. Training Loss: 0.109.. Validation Loss: 0.044.. Accuracy: 0.985\n",
            "Epoch 20/20.. Training Loss: 0.171.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.150.. Validation Loss: 0.043.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.108.. Validation Loss: 0.042.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.127.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.175.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.149.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.132.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.116.. Validation Loss: 0.042.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.134.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.149.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.090.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.143.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.118.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.140.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.120.. Validation Loss: 0.041.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.136.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.133.. Validation Loss: 0.041.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.196.. Validation Loss: 0.040.. Accuracy: 0.987\n",
            "Epoch 20/20.. Training Loss: 0.152.. Validation Loss: 0.040.. Accuracy: 0.986\n",
            "Epoch 20/20.. Training Loss: 0.137.. Validation Loss: 0.040.. Accuracy: 0.987\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9c184ed89d9c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I also stopped here because it stabalized"
      ],
      "metadata": {
        "id": "mpmjx50C0k9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss history\n",
        "plt.plot(train_loss_history, label=\"Training Loss\")\n",
        "plt.plot(valid_loss_history, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "5DQ8b3_k0w_p",
        "outputId": "f0d3b4f3-bf19-4dad-c892-229663d50800"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83e7807-a407-4f9f-99e5-25834005a9ab",
        "id": "0MG4lGKY_xoF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.987\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0\n",
        "accuracy = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images.requires_grad = True\n",
        "\n",
        "        logits = model(images)\n",
        "        batch_loss = criterion(logits, labels)\n",
        "\n",
        "        test_loss += batch_loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        probs = torch.exp(logits)\n",
        "        _, top_class = probs.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "print(f\"Test accuracy: {accuracy/len(test_loader):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDQNK6ELl2Yz"
      },
      "source": [
        "## Saving your model\n",
        "Using `torch.save`, save your model for future loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NQWv4isdl2Yz"
      },
      "outputs": [],
      "source": [
        "# Save the checkpoint\n",
        "model.class_to_idx = train_data.class_to_idx\n",
        "torch.save({\n",
        "            \"epochs\": epochs,\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"class_to_idx\": model.class_to_idx\n",
        "            }, \"checkpoint.pth\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}